{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "import random\n",
    "#from data_utils.py import load_CIFAR10\n",
    "\n",
    "params = {}\n",
    "params['batch_size'] = 100\n",
    "params['num_epochs'] = 100\n",
    "params['learning_rate'] = 1e-2\n",
    "params['activation'] = 'relu'\n",
    "params['optimizer'] = 'sgd'\n",
    "params['layers'] = [4096, 4096]\n",
    "params['output_dim'] = 10\n",
    "params['input_dim'] = 28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(activation, layer_dims, input_dims, num_classes):\n",
    "    \"\"\" \n",
    "    layer_dims: excluding input and output dimensions. \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(layer_dims[0],input_dim=input_dims))   \n",
    "    for i in range(1,len(layer_dims)):\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dense(layer_dims[i]))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "def loadData():\n",
    "    \n",
    "    num_classes = 10\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    \n",
    "    Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "    Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "    \n",
    "    num_rows = X_train.shape[1]\n",
    "    num_cols = X_train.shape[2]\n",
    "    #num_channels = X_train.shape[3]\n",
    "    input_dims = num_rows*num_cols \n",
    "    print(X_train.shape)\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], input_dims)\n",
    "    X_test = X_test.reshape(X_test.shape[0], input_dims)\n",
    "    \n",
    "    X_train = X_train.astype('float32')/255\n",
    "    X_test = X_test.astype('float32')/255\n",
    "                          \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = loadData()\n",
    "data_mean = np.mean(X_train)\n",
    "data_std_dev = np.std(X_train)\n",
    "\n",
    "def Add_noise(p, x):\n",
    "        data = x\n",
    "        num = int(p*len(x))\n",
    "        ix = random.sample(range(0, len(x)), num)\n",
    "        for i in ix:\n",
    "            randX = data_std_dev*np.random.randn(1, x.shape[1]) + data_mean\n",
    "            data[i] = randX\n",
    "        return data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.9806 - acc: 0.2873 - val_loss: 0.7888 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.1973 - acc: 0.6162 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.9125 - acc: 0.7193 - val_loss: 0.0483 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.7654 - acc: 0.7678 - val_loss: 0.0565 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.6876 - acc: 0.7925 - val_loss: 0.0441 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6421 - acc: 0.8092 - val_loss: 0.0410 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.6113 - acc: 0.8197 - val_loss: 0.0380 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5877 - acc: 0.8278 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.5696 - acc: 0.8338 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.5551 - acc: 0.8387 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.5429 - acc: 0.8421 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.5324 - acc: 0.8455 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.5236 - acc: 0.8489 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.5158 - acc: 0.8513 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.5088 - acc: 0.8532 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.5027 - acc: 0.8554 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.4968 - acc: 0.8571 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.4920 - acc: 0.8593 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.4874 - acc: 0.8599 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.4835 - acc: 0.8610 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.4799 - acc: 0.8624 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.4764 - acc: 0.8630 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.4735 - acc: 0.8654 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.4708 - acc: 0.8650 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.4684 - acc: 0.8660 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.4658 - acc: 0.8669 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.4637 - acc: 0.8672 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.4616 - acc: 0.8677 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.4599 - acc: 0.8683 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.4578 - acc: 0.8691 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.4560 - acc: 0.8701 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.4542 - acc: 0.8697 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.4524 - acc: 0.8709 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.4513 - acc: 0.8706 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.4503 - acc: 0.8718 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.4489 - acc: 0.8720 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.4472 - acc: 0.8716 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.4462 - acc: 0.8725 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.4446 - acc: 0.8730 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.4437 - acc: 0.8727 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.4424 - acc: 0.8736 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.4410 - acc: 0.8740 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.4401 - acc: 0.8746 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.4392 - acc: 0.8744 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.4384 - acc: 0.8746 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.4369 - acc: 0.8745 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4362 - acc: 0.8754 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.4355 - acc: 0.8756 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.4344 - acc: 0.8764 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.4333 - acc: 0.8761 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4327 - acc: 0.8766 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.4319 - acc: 0.8763 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4314 - acc: 0.8773 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.4304 - acc: 0.8769 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.4302 - acc: 0.8774 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4290 - acc: 0.8782 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.4284 - acc: 0.8776 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.4278 - acc: 0.8779 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4271 - acc: 0.8773 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.4262 - acc: 0.8777 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.4257 - acc: 0.8786 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4255 - acc: 0.8780 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4246 - acc: 0.8789 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4245 - acc: 0.8786 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4238 - acc: 0.8778 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4233 - acc: 0.8785 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.4228 - acc: 0.8794 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.4223 - acc: 0.8794 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.4219 - acc: 0.8796 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.4212 - acc: 0.8800 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.4208 - acc: 0.8795 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.4207 - acc: 0.8800 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.4200 - acc: 0.8806 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.4194 - acc: 0.8797 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.4192 - acc: 0.8795 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.4188 - acc: 0.8800 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.4187 - acc: 0.8801 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.4177 - acc: 0.8806 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.4180 - acc: 0.8810 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.4171 - acc: 0.8811 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.4169 - acc: 0.8812 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.4161 - acc: 0.8813 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.4161 - acc: 0.8813 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.4160 - acc: 0.8809 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.4152 - acc: 0.8821 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.4150 - acc: 0.8816 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.4146 - acc: 0.8816 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.4146 - acc: 0.8816 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.4142 - acc: 0.8818 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.4136 - acc: 0.8821 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.4133 - acc: 0.8827 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.4133 - acc: 0.8812 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.4126 - acc: 0.8820 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.4123 - acc: 0.8819 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.4121 - acc: 0.8831 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.4118 - acc: 0.8824 - val_loss: 0.0131 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 1s - loss: 0.4115 - acc: 0.8828 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.4111 - acc: 0.8826 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.4112 - acc: 0.8828 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.4107 - acc: 0.8819 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.5021 - acc: 0.5320 - val_loss: 0.4606 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.5843 - acc: 0.8406 - val_loss: 0.0706 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4279 - acc: 0.8794 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3715 - acc: 0.8939 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3402 - acc: 0.9040 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3193 - acc: 0.9090 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3037 - acc: 0.9130 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2914 - acc: 0.9169 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2812 - acc: 0.9196 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2723 - acc: 0.9229 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2647 - acc: 0.9244 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2576 - acc: 0.9269 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.2512 - acc: 0.9278 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.2455 - acc: 0.9301 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2399 - acc: 0.9319 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.2351 - acc: 0.9338 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.2303 - acc: 0.9350 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.2259 - acc: 0.9361 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2217 - acc: 0.9372 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.2176 - acc: 0.9389 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.2137 - acc: 0.9396 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.2102 - acc: 0.9407 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.2067 - acc: 0.9415 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.2034 - acc: 0.9428 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.2005 - acc: 0.9435 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.1975 - acc: 0.9440 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.1950 - acc: 0.9450 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.1921 - acc: 0.9459 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1895 - acc: 0.9462 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.1872 - acc: 0.9469 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.1849 - acc: 0.9475 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.1828 - acc: 0.9485 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.1806 - acc: 0.9489 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.1786 - acc: 0.9492 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1769 - acc: 0.9496 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1751 - acc: 0.9503 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.1732 - acc: 0.9511 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.1716 - acc: 0.9514 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.1700 - acc: 0.9520 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.1684 - acc: 0.9522 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.1670 - acc: 0.9525 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.1657 - acc: 0.9533 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.1640 - acc: 0.9534 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.1630 - acc: 0.9544 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.1616 - acc: 0.9541 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.1604 - acc: 0.9545 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.1594 - acc: 0.9552 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.1580 - acc: 0.9549 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.1569 - acc: 0.9556 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.1558 - acc: 0.9561 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.1549 - acc: 0.9560 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.1540 - acc: 0.9563 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.1526 - acc: 0.9568 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.1517 - acc: 0.9572 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.1504 - acc: 0.9576 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.1497 - acc: 0.9579 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.1490 - acc: 0.9573 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.1479 - acc: 0.9578 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.1472 - acc: 0.9579 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.1459 - acc: 0.9582 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.1452 - acc: 0.9584 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.1445 - acc: 0.9586 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.1435 - acc: 0.9588 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.1428 - acc: 0.9588 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.1416 - acc: 0.9593 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.1409 - acc: 0.9598 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.1401 - acc: 0.9597 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.1393 - acc: 0.9600 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.1387 - acc: 0.9601 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.1380 - acc: 0.9603 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.1372 - acc: 0.9602 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.1363 - acc: 0.9604 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.1357 - acc: 0.9609 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.1349 - acc: 0.9613 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.1343 - acc: 0.9614 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.1335 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.1331 - acc: 0.9616 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.1323 - acc: 0.9616 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.1316 - acc: 0.9615 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.1311 - acc: 0.9619 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.1303 - acc: 0.9627 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.1297 - acc: 0.9621 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.1295 - acc: 0.9625 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.1286 - acc: 0.9632 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.1279 - acc: 0.9635 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.1273 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.1268 - acc: 0.9636 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.1261 - acc: 0.9638 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.1256 - acc: 0.9641 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.1250 - acc: 0.9641 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.1247 - acc: 0.9641 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.1241 - acc: 0.9641 - val_loss: 0.0020 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      " - 1s - loss: 0.1235 - acc: 0.9643 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.1230 - acc: 0.9647 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.1226 - acc: 0.9644 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.1221 - acc: 0.9647 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.1217 - acc: 0.9645 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1213 - acc: 0.9649 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.1208 - acc: 0.9655 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.1200 - acc: 0.9654 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.9921 - acc: 0.7435 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4288 - acc: 0.8848 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3572 - acc: 0.9006 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3242 - acc: 0.9083 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3019 - acc: 0.9145 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2836 - acc: 0.9192 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2681 - acc: 0.9238 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2537 - acc: 0.9278 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2403 - acc: 0.9319 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2281 - acc: 0.9353 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2169 - acc: 0.9391 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2068 - acc: 0.9415 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1972 - acc: 0.9443 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1888 - acc: 0.9467 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1815 - acc: 0.9489 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1747 - acc: 0.9499 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1684 - acc: 0.9520 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1627 - acc: 0.9537 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.1573 - acc: 0.9550 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.1523 - acc: 0.9563 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.1480 - acc: 0.9575 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.1437 - acc: 0.9588 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.1395 - acc: 0.9606 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.1359 - acc: 0.9613 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.1322 - acc: 0.9626 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.1288 - acc: 0.9633 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.1255 - acc: 0.9645 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.1222 - acc: 0.9652 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1192 - acc: 0.9662 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.1165 - acc: 0.9671 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.1138 - acc: 0.9675 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.1113 - acc: 0.9685 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.1087 - acc: 0.9685 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.1061 - acc: 0.9695 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1040 - acc: 0.9700 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1017 - acc: 0.9709 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0994 - acc: 0.9714 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0975 - acc: 0.9722 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0955 - acc: 0.9727 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0936 - acc: 0.9732 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0918 - acc: 0.9738 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0902 - acc: 0.9744 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0884 - acc: 0.9748 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0866 - acc: 0.9757 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0850 - acc: 0.9760 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0835 - acc: 0.9763 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0819 - acc: 0.9767 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0803 - acc: 0.9773 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.0789 - acc: 0.9779 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.0774 - acc: 0.9780 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.0762 - acc: 0.9783 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.0747 - acc: 0.9792 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0734 - acc: 0.9796 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0723 - acc: 0.9798 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0710 - acc: 0.9803 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0697 - acc: 0.9805 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0687 - acc: 0.9807 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0673 - acc: 0.9811 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0664 - acc: 0.9816 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0654 - acc: 0.9818 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0641 - acc: 0.9820 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0632 - acc: 0.9826 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0621 - acc: 0.9827 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0610 - acc: 0.9832 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0602 - acc: 0.9834 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0592 - acc: 0.9836 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.0584 - acc: 0.9838 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0572 - acc: 0.9842 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0566 - acc: 0.9844 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0556 - acc: 0.9845 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.0548 - acc: 0.9848 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0540 - acc: 0.9853 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0532 - acc: 0.9856 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0524 - acc: 0.9857 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0516 - acc: 0.9860 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0509 - acc: 0.9862 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0501 - acc: 0.9866 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0493 - acc: 0.9868 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.0486 - acc: 0.9871 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0479 - acc: 0.9873 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0471 - acc: 0.9874 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.0464 - acc: 0.9877 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0459 - acc: 0.9879 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0453 - acc: 0.9883 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.0447 - acc: 0.9885 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.0440 - acc: 0.9886 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.0434 - acc: 0.9886 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.0428 - acc: 0.9889 - val_loss: 0.0019 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      " - 1s - loss: 0.0422 - acc: 0.9888 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.0416 - acc: 0.9895 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.0410 - acc: 0.9892 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.0405 - acc: 0.9897 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.0399 - acc: 0.9898 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.0394 - acc: 0.9900 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.0388 - acc: 0.9901 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.0382 - acc: 0.9905 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.0377 - acc: 0.9906 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.0373 - acc: 0.9902 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.0367 - acc: 0.9906 - val_loss: 8.1030e-04 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.0361 - acc: 0.9907 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.8377 - acc: 0.8033 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3913 - acc: 0.8936 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.3299 - acc: 0.9074 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2971 - acc: 0.9160 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.2734 - acc: 0.9234 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2541 - acc: 0.9285 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2377 - acc: 0.9330 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2231 - acc: 0.9369 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.2103 - acc: 0.9409 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1986 - acc: 0.9438 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1880 - acc: 0.9474 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1782 - acc: 0.9503 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1695 - acc: 0.9531 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1613 - acc: 0.9552 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1537 - acc: 0.9570 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.1471 - acc: 0.9591 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.1409 - acc: 0.9607 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.1350 - acc: 0.9627 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.1296 - acc: 0.9644 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.1246 - acc: 0.9655 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.1197 - acc: 0.9672 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.1154 - acc: 0.9680 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.1111 - acc: 0.9689 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1073 - acc: 0.9701 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 4s - loss: 0.1034 - acc: 0.9714 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 4s - loss: 0.1001 - acc: 0.9722 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 4s - loss: 0.0970 - acc: 0.9731 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 4s - loss: 0.0937 - acc: 0.9742 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 4s - loss: 0.0908 - acc: 0.9752 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 4s - loss: 0.0880 - acc: 0.9759 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 4s - loss: 0.0853 - acc: 0.9766 - val_loss: 8.4800e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.0829 - acc: 0.9771 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 4s - loss: 0.0804 - acc: 0.9781 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 4s - loss: 0.0780 - acc: 0.9785 - val_loss: 7.9574e-04 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.0757 - acc: 0.9793 - val_loss: 9.4279e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 4s - loss: 0.0737 - acc: 0.9796 - val_loss: 7.3335e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 4s - loss: 0.0717 - acc: 0.9802 - val_loss: 8.8278e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 6s - loss: 0.0697 - acc: 0.9807 - val_loss: 9.5562e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 7s - loss: 0.0679 - acc: 0.9816 - val_loss: 7.3251e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 5s - loss: 0.0661 - acc: 0.9819 - val_loss: 7.9240e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 4s - loss: 0.0644 - acc: 0.9821 - val_loss: 7.7087e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 4s - loss: 0.0628 - acc: 0.9828 - val_loss: 5.6801e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 4s - loss: 0.0611 - acc: 0.9838 - val_loss: 7.7528e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 5s - loss: 0.0596 - acc: 0.9838 - val_loss: 5.8102e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.0581 - acc: 0.9845 - val_loss: 5.2054e-04 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.0567 - acc: 0.9850 - val_loss: 4.5811e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 4s - loss: 0.0552 - acc: 0.9854 - val_loss: 4.1380e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 4s - loss: 0.0539 - acc: 0.9857 - val_loss: 5.3665e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 4s - loss: 0.0526 - acc: 0.9861 - val_loss: 3.6652e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 4s - loss: 0.0514 - acc: 0.9862 - val_loss: 3.0647e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 4s - loss: 0.0501 - acc: 0.9866 - val_loss: 3.6145e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 5s - loss: 0.0490 - acc: 0.9873 - val_loss: 3.7808e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.0478 - acc: 0.9877 - val_loss: 2.1979e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 4s - loss: 0.0467 - acc: 0.9879 - val_loss: 3.2532e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 4s - loss: 0.0457 - acc: 0.9883 - val_loss: 1.9242e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 5s - loss: 0.0446 - acc: 0.9886 - val_loss: 3.1762e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 5s - loss: 0.0436 - acc: 0.9892 - val_loss: 2.5729e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 4s - loss: 0.0427 - acc: 0.9895 - val_loss: 2.8555e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 4s - loss: 0.0417 - acc: 0.9899 - val_loss: 1.6846e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 5s - loss: 0.0408 - acc: 0.9901 - val_loss: 2.5085e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 4s - loss: 0.0398 - acc: 0.9904 - val_loss: 2.0345e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 4s - loss: 0.0390 - acc: 0.9908 - val_loss: 2.4250e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 4s - loss: 0.0381 - acc: 0.9909 - val_loss: 2.1883e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 4s - loss: 0.0372 - acc: 0.9913 - val_loss: 2.2992e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 4s - loss: 0.0365 - acc: 0.9916 - val_loss: 2.8179e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 4s - loss: 0.0357 - acc: 0.9916 - val_loss: 2.0214e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.0348 - acc: 0.9920 - val_loss: 2.9455e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 4s - loss: 0.0342 - acc: 0.9924 - val_loss: 1.5486e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.0333 - acc: 0.9925 - val_loss: 2.4876e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 5s - loss: 0.0328 - acc: 0.9927 - val_loss: 1.7913e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.0320 - acc: 0.9928 - val_loss: 1.5069e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 4s - loss: 0.0313 - acc: 0.9931 - val_loss: 1.3770e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 4s - loss: 0.0307 - acc: 0.9931 - val_loss: 1.4139e-04 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.0300 - acc: 0.9933 - val_loss: 1.4163e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.0294 - acc: 0.9937 - val_loss: 1.2160e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.0289 - acc: 0.9938 - val_loss: 1.7251e-04 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.0282 - acc: 0.9940 - val_loss: 1.8688e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 4s - loss: 0.0277 - acc: 0.9942 - val_loss: 1.1814e-04 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.0270 - acc: 0.9943 - val_loss: 1.4282e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0265 - acc: 0.9946 - val_loss: 1.1540e-04 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.0261 - acc: 0.9945 - val_loss: 1.2518e-04 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.0254 - acc: 0.9949 - val_loss: 1.1302e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      " - 4s - loss: 0.0250 - acc: 0.9951 - val_loss: 9.7637e-05 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 4s - loss: 0.0245 - acc: 0.9950 - val_loss: 9.5372e-05 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.0240 - acc: 0.9953 - val_loss: 1.2315e-04 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.0234 - acc: 0.9956 - val_loss: 5.8712e-05 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.0230 - acc: 0.9955 - val_loss: 6.6104e-05 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.0227 - acc: 0.9957 - val_loss: 6.4614e-05 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.0222 - acc: 0.9959 - val_loss: 1.0503e-04 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.0216 - acc: 0.9962 - val_loss: 4.7327e-05 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.0213 - acc: 0.9964 - val_loss: 5.9964e-05 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.0209 - acc: 0.9962 - val_loss: 5.8295e-05 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.0205 - acc: 0.9965 - val_loss: 6.1514e-05 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0201 - acc: 0.9966 - val_loss: 6.5686e-05 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.0197 - acc: 0.9968 - val_loss: 4.4645e-05 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.0193 - acc: 0.9967 - val_loss: 9.1020e-05 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.0190 - acc: 0.9968 - val_loss: 5.4361e-05 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.0186 - acc: 0.9971 - val_loss: 5.1857e-05 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.0183 - acc: 0.9972 - val_loss: 4.3274e-05 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.0179 - acc: 0.9972 - val_loss: 6.0024e-05 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.7538 - acc: 0.8279 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 14s - loss: 0.3674 - acc: 0.8993 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 14s - loss: 0.3106 - acc: 0.9130 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 16s - loss: 0.2788 - acc: 0.9217 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 15s - loss: 0.2559 - acc: 0.9281 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 13s - loss: 0.2371 - acc: 0.9338 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 15s - loss: 0.2209 - acc: 0.9382 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 13s - loss: 0.2068 - acc: 0.9424 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 13s - loss: 0.1944 - acc: 0.9460 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 13s - loss: 0.1830 - acc: 0.9482 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 13s - loss: 0.1730 - acc: 0.9524 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 13s - loss: 0.1636 - acc: 0.9540 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 13s - loss: 0.1552 - acc: 0.9569 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 13s - loss: 0.1475 - acc: 0.9593 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 15s - loss: 0.1405 - acc: 0.9606 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 13s - loss: 0.1340 - acc: 0.9629 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 13s - loss: 0.1277 - acc: 0.9648 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 13s - loss: 0.1223 - acc: 0.9664 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 15s - loss: 0.1169 - acc: 0.9678 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 14s - loss: 0.1119 - acc: 0.9691 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 14s - loss: 0.1072 - acc: 0.9703 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 14s - loss: 0.1031 - acc: 0.9713 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 13s - loss: 0.0990 - acc: 0.9729 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 13s - loss: 0.0952 - acc: 0.9737 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 13s - loss: 0.0916 - acc: 0.9748 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 14s - loss: 0.0881 - acc: 0.9762 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 14s - loss: 0.0849 - acc: 0.9769 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 14s - loss: 0.0818 - acc: 0.9775 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 15s - loss: 0.0790 - acc: 0.9786 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 15s - loss: 0.0762 - acc: 0.9794 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 16s - loss: 0.0736 - acc: 0.9801 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 16s - loss: 0.0712 - acc: 0.9810 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 17s - loss: 0.0687 - acc: 0.9815 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 17s - loss: 0.0665 - acc: 0.9822 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 18s - loss: 0.0644 - acc: 0.9829 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 18s - loss: 0.0624 - acc: 0.9832 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 18s - loss: 0.0603 - acc: 0.9840 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 18s - loss: 0.0584 - acc: 0.9852 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 18s - loss: 0.0568 - acc: 0.9854 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 18s - loss: 0.0550 - acc: 0.9857 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 18s - loss: 0.0533 - acc: 0.9867 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 18s - loss: 0.0518 - acc: 0.9866 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 18s - loss: 0.0502 - acc: 0.9876 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 16s - loss: 0.0488 - acc: 0.9880 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 15s - loss: 0.0474 - acc: 0.9887 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 14s - loss: 0.0460 - acc: 0.9886 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 16s - loss: 0.0446 - acc: 0.9895 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 15s - loss: 0.0433 - acc: 0.9895 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 26s - loss: 0.0422 - acc: 0.9901 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 15s - loss: 0.0411 - acc: 0.9903 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 14s - loss: 0.0399 - acc: 0.9907 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 15s - loss: 0.0389 - acc: 0.9909 - val_loss: 7.4707e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 13s - loss: 0.0378 - acc: 0.9914 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 13s - loss: 0.0367 - acc: 0.9915 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 13s - loss: 0.0358 - acc: 0.9917 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 13s - loss: 0.0348 - acc: 0.9922 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 13s - loss: 0.0339 - acc: 0.9924 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 13s - loss: 0.0330 - acc: 0.9927 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 13s - loss: 0.0322 - acc: 0.9928 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 13s - loss: 0.0313 - acc: 0.9931 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 13s - loss: 0.0305 - acc: 0.9935 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 13s - loss: 0.0297 - acc: 0.9936 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 14s - loss: 0.0289 - acc: 0.9939 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 13s - loss: 0.0282 - acc: 0.9942 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 13s - loss: 0.0275 - acc: 0.9944 - val_loss: 8.3935e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 13s - loss: 0.0268 - acc: 0.9946 - val_loss: 8.4686e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 14s - loss: 0.0261 - acc: 0.9948 - val_loss: 9.0867e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 13s - loss: 0.0255 - acc: 0.9951 - val_loss: 8.0206e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 14s - loss: 0.0249 - acc: 0.9954 - val_loss: 6.9130e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 14s - loss: 0.0242 - acc: 0.9956 - val_loss: 7.7289e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 15s - loss: 0.0237 - acc: 0.9956 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 14s - loss: 0.0231 - acc: 0.9959 - val_loss: 8.2825e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 13s - loss: 0.0226 - acc: 0.9961 - val_loss: 5.7941e-04 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 13s - loss: 0.0220 - acc: 0.9963 - val_loss: 7.5458e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 14s - loss: 0.0214 - acc: 0.9964 - val_loss: 7.7003e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 14s - loss: 0.0210 - acc: 0.9965 - val_loss: 6.1579e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      " - 16s - loss: 0.0204 - acc: 0.9968 - val_loss: 8.4460e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 16s - loss: 0.0200 - acc: 0.9969 - val_loss: 5.7124e-04 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 17s - loss: 0.0195 - acc: 0.9968 - val_loss: 6.2312e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 15s - loss: 0.0190 - acc: 0.9971 - val_loss: 7.7349e-04 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 15s - loss: 0.0186 - acc: 0.9972 - val_loss: 7.4319e-04 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 15s - loss: 0.0182 - acc: 0.9974 - val_loss: 5.4154e-04 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 16s - loss: 0.0178 - acc: 0.9975 - val_loss: 5.9694e-04 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 15s - loss: 0.0174 - acc: 0.9975 - val_loss: 5.1732e-04 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 15s - loss: 0.0170 - acc: 0.9977 - val_loss: 6.4209e-04 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 15s - loss: 0.0166 - acc: 0.9976 - val_loss: 6.3266e-04 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 15s - loss: 0.0162 - acc: 0.9978 - val_loss: 5.0772e-04 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 16s - loss: 0.0159 - acc: 0.9979 - val_loss: 4.7898e-04 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 14s - loss: 0.0155 - acc: 0.9981 - val_loss: 5.7917e-04 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 14s - loss: 0.0152 - acc: 0.9982 - val_loss: 6.7471e-04 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 14s - loss: 0.0149 - acc: 0.9982 - val_loss: 5.6384e-04 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 14s - loss: 0.0146 - acc: 0.9983 - val_loss: 4.3193e-04 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 14s - loss: 0.0143 - acc: 0.9983 - val_loss: 4.5346e-04 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 14s - loss: 0.0139 - acc: 0.9985 - val_loss: 4.1476e-04 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 14s - loss: 0.0137 - acc: 0.9984 - val_loss: 4.3658e-04 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 14s - loss: 0.0134 - acc: 0.9986 - val_loss: 3.7069e-04 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 14s - loss: 0.0131 - acc: 0.9987 - val_loss: 4.9120e-04 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 14s - loss: 0.0129 - acc: 0.9987 - val_loss: 3.1226e-04 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 14s - loss: 0.0126 - acc: 0.9987 - val_loss: 3.7427e-04 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 14s - loss: 0.0123 - acc: 0.9987 - val_loss: 3.9663e-04 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.1341 - acc: 0.2055 - val_loss: 0.6131 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.6637 - acc: 0.4145 - val_loss: 0.2793 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.4100 - acc: 0.5268 - val_loss: 0.1890 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.3150 - acc: 0.5540 - val_loss: 0.1371 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.2504 - acc: 0.5704 - val_loss: 0.1093 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.2049 - acc: 0.5902 - val_loss: 0.0897 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.1617 - acc: 0.6143 - val_loss: 0.0797 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.1182 - acc: 0.6338 - val_loss: 0.0753 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.0769 - acc: 0.6465 - val_loss: 0.0658 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.0394 - acc: 0.6597 - val_loss: 0.0608 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.0062 - acc: 0.6685 - val_loss: 0.0587 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.9762 - acc: 0.6769 - val_loss: 0.0578 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.9498 - acc: 0.6861 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.9278 - acc: 0.6933 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.9111 - acc: 0.6979 - val_loss: 0.0516 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.8994 - acc: 0.7006 - val_loss: 0.0432 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.8908 - acc: 0.7020 - val_loss: 0.0439 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.8847 - acc: 0.7036 - val_loss: 0.0507 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.8795 - acc: 0.7043 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.8753 - acc: 0.7062 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.8717 - acc: 0.7071 - val_loss: 0.0435 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.8682 - acc: 0.7086 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.8656 - acc: 0.7087 - val_loss: 0.0387 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.8629 - acc: 0.7099 - val_loss: 0.0417 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.8608 - acc: 0.7099 - val_loss: 0.0381 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.8586 - acc: 0.7103 - val_loss: 0.0361 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.8566 - acc: 0.7113 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.8549 - acc: 0.7117 - val_loss: 0.0361 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.8534 - acc: 0.7118 - val_loss: 0.0355 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.8517 - acc: 0.7124 - val_loss: 0.0344 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.8504 - acc: 0.7126 - val_loss: 0.0340 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.8488 - acc: 0.7130 - val_loss: 0.0312 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.8477 - acc: 0.7138 - val_loss: 0.0357 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.8463 - acc: 0.7132 - val_loss: 0.0336 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.8450 - acc: 0.7141 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.8436 - acc: 0.7139 - val_loss: 0.0317 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.8427 - acc: 0.7140 - val_loss: 0.0323 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.8415 - acc: 0.7148 - val_loss: 0.0359 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.8403 - acc: 0.7148 - val_loss: 0.0305 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.8397 - acc: 0.7142 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.8382 - acc: 0.7147 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.8374 - acc: 0.7153 - val_loss: 0.0300 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.8365 - acc: 0.7154 - val_loss: 0.0331 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.8354 - acc: 0.7157 - val_loss: 0.0300 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.8350 - acc: 0.7154 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.8337 - acc: 0.7165 - val_loss: 0.0361 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.8333 - acc: 0.7170 - val_loss: 0.0264 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.8323 - acc: 0.7169 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.8313 - acc: 0.7168 - val_loss: 0.0266 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.8308 - acc: 0.7168 - val_loss: 0.0265 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.8300 - acc: 0.7170 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.8291 - acc: 0.7175 - val_loss: 0.0331 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.8284 - acc: 0.7183 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.8280 - acc: 0.7179 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.8275 - acc: 0.7175 - val_loss: 0.0278 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.8262 - acc: 0.7180 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.8260 - acc: 0.7185 - val_loss: 0.0344 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.8252 - acc: 0.7188 - val_loss: 0.0264 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.8245 - acc: 0.7196 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.8243 - acc: 0.7189 - val_loss: 0.0278 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.8236 - acc: 0.7186 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.8229 - acc: 0.7202 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.8225 - acc: 0.7204 - val_loss: 0.0276 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.8222 - acc: 0.7194 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.8210 - acc: 0.7193 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.8206 - acc: 0.7191 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.8203 - acc: 0.7204 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.8198 - acc: 0.7203 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.8194 - acc: 0.7206 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.8188 - acc: 0.7206 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.8183 - acc: 0.7205 - val_loss: 0.0199 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      " - 1s - loss: 0.8181 - acc: 0.7208 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.8176 - acc: 0.7208 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.8174 - acc: 0.7209 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.8169 - acc: 0.7206 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.8164 - acc: 0.7210 - val_loss: 0.0226 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.8160 - acc: 0.7205 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.8154 - acc: 0.7208 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.8150 - acc: 0.7214 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.8150 - acc: 0.7215 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.8146 - acc: 0.7217 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.8139 - acc: 0.7218 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.8138 - acc: 0.7208 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.8136 - acc: 0.7215 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.8134 - acc: 0.7220 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.8128 - acc: 0.7213 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.8123 - acc: 0.7221 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.8127 - acc: 0.7216 - val_loss: 0.0248 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.8123 - acc: 0.7211 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.8116 - acc: 0.7226 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.8110 - acc: 0.7217 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.8111 - acc: 0.7224 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.8107 - acc: 0.7217 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.8102 - acc: 0.7229 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.8100 - acc: 0.7230 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.8100 - acc: 0.7224 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.8095 - acc: 0.7221 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.8095 - acc: 0.7217 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.8093 - acc: 0.7230 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.8092 - acc: 0.7219 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.5979 - acc: 0.5043 - val_loss: 0.1058 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.0047 - acc: 0.6850 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.8822 - acc: 0.7157 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.8207 - acc: 0.7307 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.7815 - acc: 0.7374 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.7561 - acc: 0.7420 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.7383 - acc: 0.7455 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.7245 - acc: 0.7499 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.7136 - acc: 0.7525 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.7044 - acc: 0.7553 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.6961 - acc: 0.7590 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.6887 - acc: 0.7613 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.6820 - acc: 0.7637 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.6757 - acc: 0.7654 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.6698 - acc: 0.7671 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.6643 - acc: 0.7696 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.6591 - acc: 0.7710 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.6541 - acc: 0.7723 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.6493 - acc: 0.7739 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.6445 - acc: 0.7753 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.6401 - acc: 0.7771 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.6359 - acc: 0.7778 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.6318 - acc: 0.7794 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.6277 - acc: 0.7805 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.6242 - acc: 0.7813 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.6206 - acc: 0.7823 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.6170 - acc: 0.7841 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.6135 - acc: 0.7850 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.6106 - acc: 0.7863 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.6074 - acc: 0.7870 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.6047 - acc: 0.7887 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.6016 - acc: 0.7889 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.5988 - acc: 0.7900 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.5962 - acc: 0.7910 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.5936 - acc: 0.7918 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.5911 - acc: 0.7931 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.5886 - acc: 0.7936 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.5862 - acc: 0.7948 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.5840 - acc: 0.7953 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.5817 - acc: 0.7963 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.5795 - acc: 0.7966 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.5773 - acc: 0.7975 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.5752 - acc: 0.7982 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.5729 - acc: 0.7991 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.5710 - acc: 0.8001 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.5691 - acc: 0.8003 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.5671 - acc: 0.8009 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.5650 - acc: 0.8021 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.5633 - acc: 0.8025 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.5612 - acc: 0.8030 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.5594 - acc: 0.8035 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.5576 - acc: 0.8044 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.5560 - acc: 0.8047 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.5542 - acc: 0.8046 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.5522 - acc: 0.8052 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.5506 - acc: 0.8059 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.5490 - acc: 0.8071 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.5473 - acc: 0.8072 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.5458 - acc: 0.8076 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.5443 - acc: 0.8083 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.5428 - acc: 0.8087 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.5411 - acc: 0.8093 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.5396 - acc: 0.8098 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.5384 - acc: 0.8095 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.5368 - acc: 0.8107 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.5355 - acc: 0.8106 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.5339 - acc: 0.8116 - val_loss: 0.0120 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      " - 1s - loss: 0.5327 - acc: 0.8121 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.5313 - acc: 0.8125 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.5301 - acc: 0.8127 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.5289 - acc: 0.8133 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.5274 - acc: 0.8141 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.5264 - acc: 0.8146 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.5250 - acc: 0.8143 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.5240 - acc: 0.8152 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.5228 - acc: 0.8151 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.5219 - acc: 0.8159 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.5205 - acc: 0.8161 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.5191 - acc: 0.8167 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.5182 - acc: 0.8169 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.5172 - acc: 0.8168 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.5162 - acc: 0.8174 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.5152 - acc: 0.8179 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.5140 - acc: 0.8180 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.5130 - acc: 0.8187 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.5122 - acc: 0.8187 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.5111 - acc: 0.8194 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.5099 - acc: 0.8198 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.5091 - acc: 0.8200 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.5080 - acc: 0.8201 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.5073 - acc: 0.8207 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.5059 - acc: 0.8212 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.5051 - acc: 0.8212 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.5045 - acc: 0.8213 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.5035 - acc: 0.8215 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.5023 - acc: 0.8225 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.5016 - acc: 0.8221 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.5008 - acc: 0.8229 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.4999 - acc: 0.8233 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.4988 - acc: 0.8234 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.3499 - acc: 0.5935 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.8842 - acc: 0.7184 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.8133 - acc: 0.7341 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.7742 - acc: 0.7426 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.7458 - acc: 0.7484 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.7232 - acc: 0.7534 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.7044 - acc: 0.7594 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.6883 - acc: 0.7631 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.6743 - acc: 0.7672 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.6620 - acc: 0.7713 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.6507 - acc: 0.7754 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.6402 - acc: 0.7789 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.6306 - acc: 0.7818 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.6220 - acc: 0.7846 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.6136 - acc: 0.7876 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.6056 - acc: 0.7906 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.5981 - acc: 0.7932 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.5909 - acc: 0.7954 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.5839 - acc: 0.7979 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.5771 - acc: 0.8004 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.5706 - acc: 0.8029 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.5641 - acc: 0.8052 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.5578 - acc: 0.8074 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.5518 - acc: 0.8095 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.5456 - acc: 0.8120 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.5398 - acc: 0.8143 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.5339 - acc: 0.8169 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.5280 - acc: 0.8191 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.5223 - acc: 0.8211 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.5166 - acc: 0.8241 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.5110 - acc: 0.8258 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.5052 - acc: 0.8285 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.4999 - acc: 0.8304 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.4942 - acc: 0.8324 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.4888 - acc: 0.8343 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.4832 - acc: 0.8370 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.4776 - acc: 0.8385 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.4721 - acc: 0.8416 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.4666 - acc: 0.8433 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.4611 - acc: 0.8458 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.4555 - acc: 0.8479 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.4501 - acc: 0.8495 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.4445 - acc: 0.8517 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.4390 - acc: 0.8544 - val_loss: 9.6881e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.4335 - acc: 0.8564 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.4281 - acc: 0.8584 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4226 - acc: 0.8606 - val_loss: 9.4500e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.4171 - acc: 0.8625 - val_loss: 7.7069e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.4116 - acc: 0.8648 - val_loss: 8.3088e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.4060 - acc: 0.8669 - val_loss: 7.5297e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4005 - acc: 0.8692 - val_loss: 6.5634e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3950 - acc: 0.8721 - val_loss: 4.8375e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3897 - acc: 0.8735 - val_loss: 5.8787e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3842 - acc: 0.8755 - val_loss: 5.0963e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3786 - acc: 0.8775 - val_loss: 5.0009e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3729 - acc: 0.8796 - val_loss: 3.6020e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3678 - acc: 0.8812 - val_loss: 4.9162e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3621 - acc: 0.8839 - val_loss: 3.7999e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3567 - acc: 0.8859 - val_loss: 4.4946e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3515 - acc: 0.8876 - val_loss: 4.5137e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3460 - acc: 0.8895 - val_loss: 2.9884e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3407 - acc: 0.8927 - val_loss: 2.8334e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3355 - acc: 0.8940 - val_loss: 2.7189e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3300 - acc: 0.8966 - val_loss: 2.0548e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3247 - acc: 0.8981 - val_loss: 2.7601e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3196 - acc: 0.8994 - val_loss: 2.4614e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3142 - acc: 0.9018 - val_loss: 1.5904e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3093 - acc: 0.9032 - val_loss: 1.4235e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3040 - acc: 0.9055 - val_loss: 1.2744e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2985 - acc: 0.9075 - val_loss: 1.4115e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2938 - acc: 0.9092 - val_loss: 1.4819e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2887 - acc: 0.9115 - val_loss: 1.8580e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2837 - acc: 0.9135 - val_loss: 9.2213e-05 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.2786 - acc: 0.9158 - val_loss: 7.5462e-05 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.2737 - acc: 0.9178 - val_loss: 1.0109e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.2689 - acc: 0.9192 - val_loss: 1.2422e-04 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2640 - acc: 0.9210 - val_loss: 6.7832e-05 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2589 - acc: 0.9236 - val_loss: 8.7623e-05 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2542 - acc: 0.9251 - val_loss: 1.0419e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2495 - acc: 0.9270 - val_loss: 1.2935e-04 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2448 - acc: 0.9287 - val_loss: 5.4361e-05 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2401 - acc: 0.9316 - val_loss: 8.2377e-05 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2357 - acc: 0.9331 - val_loss: 4.4406e-05 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2310 - acc: 0.9347 - val_loss: 5.9845e-05 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2263 - acc: 0.9367 - val_loss: 3.4452e-05 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2219 - acc: 0.9386 - val_loss: 2.3604e-05 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2176 - acc: 0.9399 - val_loss: 3.2127e-05 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2132 - acc: 0.9417 - val_loss: 2.5153e-05 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2090 - acc: 0.9432 - val_loss: 2.6346e-05 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2048 - acc: 0.9452 - val_loss: 2.5034e-05 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2004 - acc: 0.9472 - val_loss: 3.4571e-05 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.1965 - acc: 0.9488 - val_loss: 1.6391e-05 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.1923 - acc: 0.9508 - val_loss: 2.4438e-05 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.1882 - acc: 0.9515 - val_loss: 3.0816e-05 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.1842 - acc: 0.9533 - val_loss: 1.4842e-05 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.1803 - acc: 0.9546 - val_loss: 1.2279e-05 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.1761 - acc: 0.9567 - val_loss: 1.3530e-05 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1727 - acc: 0.9574 - val_loss: 1.1683e-05 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.1690 - acc: 0.9593 - val_loss: 1.6451e-05 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.1651 - acc: 0.9607 - val_loss: 2.5869e-05 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.2560 - acc: 0.6357 - val_loss: 0.0528 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.8495 - acc: 0.7283 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.7897 - acc: 0.7420 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.7550 - acc: 0.7508 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.7279 - acc: 0.7580 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.7053 - acc: 0.7637 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.6854 - acc: 0.7698 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.6677 - acc: 0.7749 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.6518 - acc: 0.7785 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.6372 - acc: 0.7831 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.6237 - acc: 0.7875 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.6113 - acc: 0.7900 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.5992 - acc: 0.7947 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.5880 - acc: 0.7979 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.5771 - acc: 0.8022 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.5665 - acc: 0.8056 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.5563 - acc: 0.8094 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.5465 - acc: 0.8130 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.5367 - acc: 0.8166 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.5270 - acc: 0.8205 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.5174 - acc: 0.8244 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.5079 - acc: 0.8282 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.4986 - acc: 0.8325 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.4892 - acc: 0.8361 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.4799 - acc: 0.8398 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.4705 - acc: 0.8435 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.4609 - acc: 0.8478 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 3s - loss: 0.4515 - acc: 0.8515 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.4421 - acc: 0.8555 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.4325 - acc: 0.8591 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.4230 - acc: 0.8630 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.4132 - acc: 0.8672 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.4037 - acc: 0.8718 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.3937 - acc: 0.8754 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.3837 - acc: 0.8796 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.3739 - acc: 0.8834 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.3638 - acc: 0.8884 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.3535 - acc: 0.8925 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.3433 - acc: 0.8965 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.3330 - acc: 0.9009 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.3227 - acc: 0.9056 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.3124 - acc: 0.9101 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.3019 - acc: 0.9135 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.2913 - acc: 0.9186 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.2808 - acc: 0.9230 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.2704 - acc: 0.9285 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.2601 - acc: 0.9329 - val_loss: 9.4333e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.2497 - acc: 0.9374 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.2394 - acc: 0.9419 - val_loss: 9.3116e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.2293 - acc: 0.9448 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.2193 - acc: 0.9497 - val_loss: 5.0546e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.2094 - acc: 0.9533 - val_loss: 7.2702e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.1996 - acc: 0.9576 - val_loss: 3.6175e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.1900 - acc: 0.9614 - val_loss: 6.8915e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.1809 - acc: 0.9649 - val_loss: 5.2704e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.1717 - acc: 0.9686 - val_loss: 4.2895e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      " - 3s - loss: 0.1627 - acc: 0.9715 - val_loss: 2.4363e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.1544 - acc: 0.9744 - val_loss: 4.3455e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.1462 - acc: 0.9772 - val_loss: 5.3873e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.1380 - acc: 0.9796 - val_loss: 3.7999e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.1306 - acc: 0.9818 - val_loss: 4.2537e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.1232 - acc: 0.9840 - val_loss: 3.4606e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.1163 - acc: 0.9858 - val_loss: 1.9642e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.1097 - acc: 0.9875 - val_loss: 2.9199e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.1035 - acc: 0.9892 - val_loss: 1.0610e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.0976 - acc: 0.9902 - val_loss: 2.1049e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.0921 - acc: 0.9914 - val_loss: 1.6786e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.0868 - acc: 0.9925 - val_loss: 1.8008e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.0818 - acc: 0.9934 - val_loss: 1.5892e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.0772 - acc: 0.9940 - val_loss: 1.1361e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.0728 - acc: 0.9946 - val_loss: 1.6166e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.0687 - acc: 0.9953 - val_loss: 1.7662e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.0650 - acc: 0.9959 - val_loss: 1.2899e-04 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.0614 - acc: 0.9961 - val_loss: 1.7829e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.0582 - acc: 0.9962 - val_loss: 8.8874e-05 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.0552 - acc: 0.9967 - val_loss: 5.3288e-05 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.0521 - acc: 0.9970 - val_loss: 1.0563e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.0496 - acc: 0.9972 - val_loss: 1.6184e-04 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.0471 - acc: 0.9974 - val_loss: 1.2470e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0447 - acc: 0.9976 - val_loss: 9.4180e-05 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.0426 - acc: 0.9978 - val_loss: 5.2036e-05 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.0405 - acc: 0.9979 - val_loss: 1.0264e-04 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.0387 - acc: 0.9981 - val_loss: 1.1671e-04 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.0370 - acc: 0.9981 - val_loss: 6.8905e-05 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.0352 - acc: 0.9983 - val_loss: 6.5329e-05 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.0337 - acc: 0.9985 - val_loss: 4.1784e-05 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.0323 - acc: 0.9985 - val_loss: 4.1963e-05 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.0309 - acc: 0.9985 - val_loss: 6.2229e-05 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.0296 - acc: 0.9986 - val_loss: 6.0322e-05 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.0285 - acc: 0.9988 - val_loss: 3.9101e-05 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.0273 - acc: 0.9988 - val_loss: 4.1724e-05 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.0262 - acc: 0.9989 - val_loss: 3.8267e-05 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.0252 - acc: 0.9990 - val_loss: 3.0637e-05 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0243 - acc: 0.9991 - val_loss: 2.9922e-05 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.0234 - acc: 0.9992 - val_loss: 2.7240e-05 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.0226 - acc: 0.9992 - val_loss: 3.4691e-05 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.0217 - acc: 0.9993 - val_loss: 3.7194e-05 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.0210 - acc: 0.9992 - val_loss: 2.6226e-05 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.0203 - acc: 0.9994 - val_loss: 3.4691e-05 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.0195 - acc: 0.9994 - val_loss: 2.8372e-05 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.1402 - acc: 0.6735 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 13s - loss: 0.8053 - acc: 0.7371 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 13s - loss: 0.7552 - acc: 0.7507 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 14s - loss: 0.7252 - acc: 0.7583 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 14s - loss: 0.7011 - acc: 0.7650 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 14s - loss: 0.6799 - acc: 0.7726 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 14s - loss: 0.6605 - acc: 0.7773 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 14s - loss: 0.6426 - acc: 0.7834 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 14s - loss: 0.6257 - acc: 0.7885 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 14s - loss: 0.6095 - acc: 0.7934 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 14s - loss: 0.5942 - acc: 0.7985 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 15s - loss: 0.5794 - acc: 0.8034 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 14s - loss: 0.5653 - acc: 0.8087 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 14s - loss: 0.5512 - acc: 0.8131 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 14s - loss: 0.5377 - acc: 0.8181 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 14s - loss: 0.5243 - acc: 0.8231 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 14s - loss: 0.5113 - acc: 0.8287 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 14s - loss: 0.4983 - acc: 0.8332 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 15s - loss: 0.4853 - acc: 0.8395 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 14s - loss: 0.4722 - acc: 0.8444 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 14s - loss: 0.4593 - acc: 0.8498 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 14s - loss: 0.4463 - acc: 0.8557 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 14s - loss: 0.4334 - acc: 0.8608 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 14s - loss: 0.4204 - acc: 0.8667 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 14s - loss: 0.4074 - acc: 0.8725 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 14s - loss: 0.3941 - acc: 0.8782 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 14s - loss: 0.3808 - acc: 0.8837 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 14s - loss: 0.3675 - acc: 0.8901 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 13s - loss: 0.3539 - acc: 0.8961 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 13s - loss: 0.3403 - acc: 0.9016 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 14s - loss: 0.3265 - acc: 0.9085 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 14s - loss: 0.3127 - acc: 0.9142 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 14s - loss: 0.2988 - acc: 0.9206 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 14s - loss: 0.2849 - acc: 0.9267 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 14s - loss: 0.2708 - acc: 0.9339 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 15s - loss: 0.2569 - acc: 0.9395 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 14s - loss: 0.2431 - acc: 0.9463 - val_loss: 9.1428e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 14s - loss: 0.2292 - acc: 0.9521 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 14s - loss: 0.2157 - acc: 0.9586 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 14s - loss: 0.2021 - acc: 0.9633 - val_loss: 8.7222e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 15s - loss: 0.1891 - acc: 0.9685 - val_loss: 9.6964e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 15s - loss: 0.1767 - acc: 0.9734 - val_loss: 7.0132e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 15s - loss: 0.1645 - acc: 0.9772 - val_loss: 5.7326e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 15s - loss: 0.1527 - acc: 0.9808 - val_loss: 3.7463e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 15s - loss: 0.1415 - acc: 0.9844 - val_loss: 5.6396e-04 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 15s - loss: 0.1310 - acc: 0.9869 - val_loss: 4.7272e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 14s - loss: 0.1212 - acc: 0.9893 - val_loss: 4.2954e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 14s - loss: 0.1121 - acc: 0.9911 - val_loss: 3.7135e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 14s - loss: 0.1034 - acc: 0.9924 - val_loss: 2.5711e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      " - 15s - loss: 0.0955 - acc: 0.9937 - val_loss: 3.2979e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 15s - loss: 0.0882 - acc: 0.9948 - val_loss: 2.6844e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 14s - loss: 0.0816 - acc: 0.9953 - val_loss: 1.9403e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 15s - loss: 0.0753 - acc: 0.9961 - val_loss: 2.5240e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 16s - loss: 0.0699 - acc: 0.9963 - val_loss: 2.3243e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 15s - loss: 0.0649 - acc: 0.9966 - val_loss: 1.3680e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 15s - loss: 0.0602 - acc: 0.9972 - val_loss: 1.9719e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 15s - loss: 0.0561 - acc: 0.9972 - val_loss: 2.8197e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 15s - loss: 0.0522 - acc: 0.9978 - val_loss: 1.3269e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 15s - loss: 0.0488 - acc: 0.9978 - val_loss: 1.4634e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 15s - loss: 0.0457 - acc: 0.9980 - val_loss: 1.8414e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 15s - loss: 0.0427 - acc: 0.9983 - val_loss: 6.9263e-05 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 15s - loss: 0.0403 - acc: 0.9983 - val_loss: 1.0586e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 15s - loss: 0.0378 - acc: 0.9985 - val_loss: 8.8338e-05 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 15s - loss: 0.0357 - acc: 0.9986 - val_loss: 1.5057e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 15s - loss: 0.0336 - acc: 0.9989 - val_loss: 6.0560e-05 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 15s - loss: 0.0319 - acc: 0.9989 - val_loss: 8.0827e-05 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 15s - loss: 0.0302 - acc: 0.9989 - val_loss: 8.4404e-05 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 15s - loss: 0.0286 - acc: 0.9991 - val_loss: 8.7980e-05 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 16s - loss: 0.0272 - acc: 0.9991 - val_loss: 7.2124e-05 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 16s - loss: 0.0259 - acc: 0.9993 - val_loss: 1.0795e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 15s - loss: 0.0246 - acc: 0.9993 - val_loss: 1.0980e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 15s - loss: 0.0235 - acc: 0.9993 - val_loss: 5.0129e-05 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 15s - loss: 0.0225 - acc: 0.9993 - val_loss: 7.8979e-05 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 15s - loss: 0.0214 - acc: 0.9994 - val_loss: 7.9158e-05 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 15s - loss: 0.0206 - acc: 0.9994 - val_loss: 5.9130e-05 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 15s - loss: 0.0196 - acc: 0.9995 - val_loss: 4.9056e-05 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 15s - loss: 0.0189 - acc: 0.9995 - val_loss: 4.1068e-05 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 15s - loss: 0.0181 - acc: 0.9996 - val_loss: 3.5167e-05 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 15s - loss: 0.0174 - acc: 0.9995 - val_loss: 3.2247e-05 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 15s - loss: 0.0167 - acc: 0.9997 - val_loss: 3.6359e-05 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 15s - loss: 0.0161 - acc: 0.9996 - val_loss: 3.5883e-05 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 15s - loss: 0.0155 - acc: 0.9998 - val_loss: 2.9445e-05 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 15s - loss: 0.0150 - acc: 0.9997 - val_loss: 2.6465e-05 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 15s - loss: 0.0145 - acc: 0.9998 - val_loss: 3.2127e-05 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 15s - loss: 0.0140 - acc: 0.9998 - val_loss: 2.7299e-05 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 15s - loss: 0.0135 - acc: 0.9998 - val_loss: 2.7895e-05 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 16s - loss: 0.0130 - acc: 0.9998 - val_loss: 3.1829e-05 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 16s - loss: 0.0126 - acc: 0.9999 - val_loss: 2.1935e-05 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 16s - loss: 0.0122 - acc: 0.9998 - val_loss: 2.7419e-05 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 16s - loss: 0.0119 - acc: 0.9999 - val_loss: 2.5928e-05 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 16s - loss: 0.0115 - acc: 0.9999 - val_loss: 2.6524e-05 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 16s - loss: 0.0111 - acc: 0.9999 - val_loss: 1.8478e-05 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 16s - loss: 0.0108 - acc: 0.9999 - val_loss: 2.7120e-05 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 16s - loss: 0.0105 - acc: 0.9999 - val_loss: 1.8120e-05 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 16s - loss: 0.0102 - acc: 0.9999 - val_loss: 1.7762e-05 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 16s - loss: 0.0100 - acc: 0.9999 - val_loss: 1.4305e-05 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 16s - loss: 0.0097 - acc: 0.9999 - val_loss: 2.4796e-05 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 16s - loss: 0.0094 - acc: 0.9999 - val_loss: 1.6630e-05 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 16s - loss: 0.0092 - acc: 0.9999 - val_loss: 1.3590e-05 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 16s - loss: 0.0090 - acc: 0.9999 - val_loss: 1.4305e-05 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.1804 - acc: 0.1664 - val_loss: 1.0949 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.9751 - acc: 0.2584 - val_loss: 0.7042 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.8388 - acc: 0.3298 - val_loss: 0.2946 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.7480 - acc: 0.3612 - val_loss: 0.0886 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.6838 - acc: 0.3802 - val_loss: 0.0356 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.6384 - acc: 0.3969 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.6045 - acc: 0.4103 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.5774 - acc: 0.4249 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.5547 - acc: 0.4293 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.5360 - acc: 0.4318 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.5208 - acc: 0.4369 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 1.5086 - acc: 0.4409 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 1.4988 - acc: 0.4449 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 1.4909 - acc: 0.4488 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 1.4844 - acc: 0.4521 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.4794 - acc: 0.4557 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 1.4749 - acc: 0.4570 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.4710 - acc: 0.4568 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.4675 - acc: 0.4583 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.4645 - acc: 0.4595 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.4614 - acc: 0.4610 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.4588 - acc: 0.4618 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.4566 - acc: 0.4615 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.4544 - acc: 0.4620 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.4526 - acc: 0.4626 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.4505 - acc: 0.4635 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.4486 - acc: 0.4640 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.4469 - acc: 0.4641 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.4454 - acc: 0.4649 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.4437 - acc: 0.4646 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.4425 - acc: 0.4659 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.4408 - acc: 0.4658 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.4392 - acc: 0.4669 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.4380 - acc: 0.4672 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.4368 - acc: 0.4673 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.4358 - acc: 0.4679 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.4344 - acc: 0.4699 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.4332 - acc: 0.4671 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.4323 - acc: 0.4690 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 1.4318 - acc: 0.4722 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.4306 - acc: 0.4693 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.4297 - acc: 0.4713 - val_loss: 0.0034 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      " - 1s - loss: 1.4289 - acc: 0.4732 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.4281 - acc: 0.4730 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.4272 - acc: 0.4738 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.4269 - acc: 0.4697 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.4262 - acc: 0.4744 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.4254 - acc: 0.4727 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.4247 - acc: 0.4745 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.4239 - acc: 0.4747 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.4234 - acc: 0.4747 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.4229 - acc: 0.4751 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.4223 - acc: 0.4748 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.4218 - acc: 0.4759 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.4217 - acc: 0.4746 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 2s - loss: 1.4210 - acc: 0.4762 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.4205 - acc: 0.4761 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.4197 - acc: 0.4749 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 1.4195 - acc: 0.4758 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.4191 - acc: 0.4768 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.4188 - acc: 0.4766 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.4181 - acc: 0.4764 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 2s - loss: 1.4179 - acc: 0.4773 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.4174 - acc: 0.4769 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 2s - loss: 1.4173 - acc: 0.4767 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 2s - loss: 1.4169 - acc: 0.4770 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 2s - loss: 1.4165 - acc: 0.4773 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.4161 - acc: 0.4776 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 2s - loss: 1.4159 - acc: 0.4773 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 2s - loss: 1.4154 - acc: 0.4773 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.4149 - acc: 0.4777 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.4144 - acc: 0.4779 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.4146 - acc: 0.4777 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.4142 - acc: 0.4783 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.4137 - acc: 0.4778 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.4136 - acc: 0.4785 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.4135 - acc: 0.4779 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.4129 - acc: 0.4781 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.4126 - acc: 0.4783 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.4126 - acc: 0.4782 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.4122 - acc: 0.4785 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.4121 - acc: 0.4786 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.4117 - acc: 0.4789 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.4114 - acc: 0.4792 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.4113 - acc: 0.4787 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.4111 - acc: 0.4781 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.4109 - acc: 0.4781 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.4104 - acc: 0.4794 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.4104 - acc: 0.4790 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.4103 - acc: 0.4789 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.4099 - acc: 0.4793 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.4096 - acc: 0.4791 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.4094 - acc: 0.4796 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.4094 - acc: 0.4791 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.4089 - acc: 0.4796 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.4088 - acc: 0.4794 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 1.4088 - acc: 0.4795 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.4088 - acc: 0.4800 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.4086 - acc: 0.4795 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.4083 - acc: 0.4798 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.0250 - acc: 0.3063 - val_loss: 0.2597 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.6393 - acc: 0.4343 - val_loss: 0.0438 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.5132 - acc: 0.4570 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.4567 - acc: 0.4695 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.4256 - acc: 0.4781 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.4058 - acc: 0.4834 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.3915 - acc: 0.4880 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.3805 - acc: 0.4918 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.3716 - acc: 0.4939 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.3640 - acc: 0.4962 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.3575 - acc: 0.4984 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 1.3515 - acc: 0.5009 - val_loss: 8.5641e-04 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 1.3462 - acc: 0.5024 - val_loss: 8.8844e-04 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 1.3414 - acc: 0.5040 - val_loss: 8.1256e-04 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 1.3367 - acc: 0.5064 - val_loss: 9.4267e-04 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.3321 - acc: 0.5080 - val_loss: 8.5760e-04 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 1.3280 - acc: 0.5094 - val_loss: 9.9786e-04 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.3240 - acc: 0.5111 - val_loss: 8.4448e-04 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.3202 - acc: 0.5119 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.3166 - acc: 0.5129 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.3129 - acc: 0.5141 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.3095 - acc: 0.5157 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.3064 - acc: 0.5163 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.3032 - acc: 0.5172 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.3002 - acc: 0.5193 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.2971 - acc: 0.5202 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.2943 - acc: 0.5210 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.2917 - acc: 0.5209 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.2889 - acc: 0.5225 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.2863 - acc: 0.5236 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.2836 - acc: 0.5251 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.2812 - acc: 0.5260 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.2786 - acc: 0.5266 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.2761 - acc: 0.5271 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.2738 - acc: 0.5278 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.2715 - acc: 0.5283 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 2s - loss: 1.2689 - acc: 0.5290 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 2s - loss: 1.2667 - acc: 0.5294 - val_loss: 0.0014 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      " - 2s - loss: 1.2643 - acc: 0.5301 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 2s - loss: 1.2620 - acc: 0.5309 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 2s - loss: 1.2597 - acc: 0.5317 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 2s - loss: 1.2578 - acc: 0.5322 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 2s - loss: 1.2554 - acc: 0.5335 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 2s - loss: 1.2533 - acc: 0.5331 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.2510 - acc: 0.5344 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 2s - loss: 1.2491 - acc: 0.5341 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 2s - loss: 1.2469 - acc: 0.5356 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 2s - loss: 1.2449 - acc: 0.5362 - val_loss: 9.9906e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 2s - loss: 1.2428 - acc: 0.5380 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 2s - loss: 1.2407 - acc: 0.5382 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 2s - loss: 1.2389 - acc: 0.5387 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 2s - loss: 1.2370 - acc: 0.5386 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.2350 - acc: 0.5400 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 2s - loss: 1.2330 - acc: 0.5407 - val_loss: 9.6970e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 2s - loss: 1.2310 - acc: 0.5418 - val_loss: 8.9692e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 2s - loss: 1.2295 - acc: 0.5414 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.2276 - acc: 0.5423 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.2259 - acc: 0.5428 - val_loss: 7.7122e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 2s - loss: 1.2241 - acc: 0.5431 - val_loss: 6.3308e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 2s - loss: 1.2224 - acc: 0.5437 - val_loss: 8.8880e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.2207 - acc: 0.5439 - val_loss: 7.5023e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.2191 - acc: 0.5446 - val_loss: 7.5685e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.2174 - acc: 0.5450 - val_loss: 6.7137e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.2156 - acc: 0.5461 - val_loss: 4.8423e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 2s - loss: 1.2139 - acc: 0.5462 - val_loss: 5.5108e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.2123 - acc: 0.5467 - val_loss: 6.4376e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.2107 - acc: 0.5475 - val_loss: 5.3760e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.2092 - acc: 0.5482 - val_loss: 3.8584e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.2077 - acc: 0.5485 - val_loss: 4.6789e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.2062 - acc: 0.5495 - val_loss: 4.8989e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.2045 - acc: 0.5492 - val_loss: 4.5411e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.2032 - acc: 0.5514 - val_loss: 5.3784e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.2017 - acc: 0.5510 - val_loss: 5.1571e-04 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.2000 - acc: 0.5516 - val_loss: 4.8351e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.1988 - acc: 0.5525 - val_loss: 4.1338e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.1973 - acc: 0.5521 - val_loss: 4.4451e-04 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.1958 - acc: 0.5533 - val_loss: 4.0617e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.1946 - acc: 0.5538 - val_loss: 3.7218e-04 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.1932 - acc: 0.5536 - val_loss: 4.9627e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.1918 - acc: 0.5549 - val_loss: 4.1106e-04 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.1907 - acc: 0.5545 - val_loss: 4.3318e-04 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.1891 - acc: 0.5553 - val_loss: 4.8685e-04 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 2s - loss: 1.1879 - acc: 0.5557 - val_loss: 3.1399e-04 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.1867 - acc: 0.5558 - val_loss: 4.0152e-04 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.1852 - acc: 0.5568 - val_loss: 4.3658e-04 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.1841 - acc: 0.5571 - val_loss: 3.9532e-04 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.1829 - acc: 0.5571 - val_loss: 3.8935e-04 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 2s - loss: 1.1819 - acc: 0.5581 - val_loss: 4.2442e-04 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 2s - loss: 1.1807 - acc: 0.5571 - val_loss: 4.1917e-04 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.1794 - acc: 0.5578 - val_loss: 3.1536e-04 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.1782 - acc: 0.5590 - val_loss: 3.4499e-04 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.1769 - acc: 0.5589 - val_loss: 4.9711e-04 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.1761 - acc: 0.5597 - val_loss: 4.1988e-04 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.1749 - acc: 0.5592 - val_loss: 4.7135e-04 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.1739 - acc: 0.5596 - val_loss: 3.6652e-04 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 2s - loss: 1.1729 - acc: 0.5602 - val_loss: 4.0188e-04 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 2s - loss: 1.1720 - acc: 0.5604 - val_loss: 4.2716e-04 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.1707 - acc: 0.5615 - val_loss: 3.5364e-04 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.1698 - acc: 0.5617 - val_loss: 3.3122e-04 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.1686 - acc: 0.5621 - val_loss: 4.9079e-04 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.9006 - acc: 0.3654 - val_loss: 0.2495 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.5641 - acc: 0.4616 - val_loss: 0.0761 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.4805 - acc: 0.4763 - val_loss: 0.0363 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.4341 - acc: 0.4830 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4036 - acc: 0.4890 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.3820 - acc: 0.4941 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.3655 - acc: 0.4986 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.3526 - acc: 0.5032 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.3417 - acc: 0.5060 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.3322 - acc: 0.5096 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.3237 - acc: 0.5126 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.3158 - acc: 0.5166 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.3083 - acc: 0.5194 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.3013 - acc: 0.5227 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.2945 - acc: 0.5260 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.2878 - acc: 0.5297 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.2814 - acc: 0.5330 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.2752 - acc: 0.5360 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.2690 - acc: 0.5390 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.2628 - acc: 0.5424 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.2567 - acc: 0.5450 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.2505 - acc: 0.5476 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 2s - loss: 1.2444 - acc: 0.5516 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 2s - loss: 1.2382 - acc: 0.5543 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 2s - loss: 1.2321 - acc: 0.5574 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 2s - loss: 1.2260 - acc: 0.5597 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 2s - loss: 1.2198 - acc: 0.5631 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 2s - loss: 1.2135 - acc: 0.5655 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 2s - loss: 1.2073 - acc: 0.5691 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 2s - loss: 1.2009 - acc: 0.5723 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 2s - loss: 1.1944 - acc: 0.5750 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 2s - loss: 1.1881 - acc: 0.5783 - val_loss: 0.0029 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      " - 2s - loss: 1.1814 - acc: 0.5811 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 2s - loss: 1.1748 - acc: 0.5835 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 2s - loss: 1.1681 - acc: 0.5866 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 2s - loss: 1.1613 - acc: 0.5894 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 2s - loss: 1.1545 - acc: 0.5917 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 2s - loss: 1.1477 - acc: 0.5956 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 2s - loss: 1.1409 - acc: 0.5980 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 2s - loss: 1.1339 - acc: 0.6004 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 2s - loss: 1.1267 - acc: 0.6034 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 2s - loss: 1.1196 - acc: 0.6074 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 2s - loss: 1.1124 - acc: 0.6102 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 2s - loss: 1.1051 - acc: 0.6126 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 2s - loss: 1.0979 - acc: 0.6157 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 2s - loss: 1.0905 - acc: 0.6186 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 2s - loss: 1.0832 - acc: 0.6229 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 2s - loss: 1.0758 - acc: 0.6251 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 2s - loss: 1.0681 - acc: 0.6284 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 2s - loss: 1.0608 - acc: 0.6305 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 2s - loss: 1.0533 - acc: 0.6335 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 2s - loss: 1.0457 - acc: 0.6369 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 2s - loss: 1.0380 - acc: 0.6406 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 2s - loss: 1.0306 - acc: 0.6441 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 2s - loss: 1.0228 - acc: 0.6472 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 2s - loss: 1.0151 - acc: 0.6494 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 2s - loss: 1.0077 - acc: 0.6526 - val_loss: 8.8665e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.9999 - acc: 0.6558 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.9922 - acc: 0.6587 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.9846 - acc: 0.6618 - val_loss: 8.7126e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.9771 - acc: 0.6658 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.9695 - acc: 0.6664 - val_loss: 6.3326e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.9618 - acc: 0.6710 - val_loss: 8.2587e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.9541 - acc: 0.6731 - val_loss: 7.3299e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.9466 - acc: 0.6755 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.9390 - acc: 0.6794 - val_loss: 7.2488e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.9311 - acc: 0.6807 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.9237 - acc: 0.6842 - val_loss: 6.2736e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.9162 - acc: 0.6866 - val_loss: 8.6959e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.9087 - acc: 0.6895 - val_loss: 7.5070e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.9009 - acc: 0.6923 - val_loss: 6.5646e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.8935 - acc: 0.6964 - val_loss: 6.2324e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.8861 - acc: 0.6974 - val_loss: 7.1700e-04 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.8790 - acc: 0.7003 - val_loss: 4.9591e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.8717 - acc: 0.7039 - val_loss: 6.1167e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.8645 - acc: 0.7068 - val_loss: 4.7600e-04 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.8576 - acc: 0.7088 - val_loss: 6.0410e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.8502 - acc: 0.7123 - val_loss: 5.9360e-04 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.8433 - acc: 0.7148 - val_loss: 4.5608e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.8369 - acc: 0.7165 - val_loss: 4.7135e-04 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.8299 - acc: 0.7197 - val_loss: 4.5459e-04 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.8230 - acc: 0.7224 - val_loss: 3.5340e-04 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 2s - loss: 0.8166 - acc: 0.7248 - val_loss: 3.6061e-04 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.8101 - acc: 0.7270 - val_loss: 3.8452e-04 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.8035 - acc: 0.7291 - val_loss: 3.8846e-04 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.7972 - acc: 0.7310 - val_loss: 3.9090e-04 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.7907 - acc: 0.7332 - val_loss: 4.3360e-04 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.7843 - acc: 0.7368 - val_loss: 3.9496e-04 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.7782 - acc: 0.7384 - val_loss: 2.6981e-04 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.7725 - acc: 0.7403 - val_loss: 3.7618e-04 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.7661 - acc: 0.7426 - val_loss: 2.5025e-04 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 2s - loss: 0.7604 - acc: 0.7445 - val_loss: 2.5902e-04 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.7543 - acc: 0.7466 - val_loss: 2.1239e-04 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 2s - loss: 0.7484 - acc: 0.7488 - val_loss: 3.1798e-04 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.7430 - acc: 0.7511 - val_loss: 2.1812e-04 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.7373 - acc: 0.7524 - val_loss: 2.6999e-04 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.7319 - acc: 0.7546 - val_loss: 3.2204e-04 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.7263 - acc: 0.7566 - val_loss: 1.4956e-04 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.7211 - acc: 0.7580 - val_loss: 2.1824e-04 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.7157 - acc: 0.7616 - val_loss: 1.3138e-04 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.8455 - acc: 0.3882 - val_loss: 0.0921 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.5326 - acc: 0.4678 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.4704 - acc: 0.4797 - val_loss: 0.0163 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.4342 - acc: 0.4881 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.4072 - acc: 0.4948 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.3856 - acc: 0.4994 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 3s - loss: 1.3671 - acc: 0.5048 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 3s - loss: 1.3512 - acc: 0.5096 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 3s - loss: 1.3370 - acc: 0.5144 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 3s - loss: 1.3239 - acc: 0.5199 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 3s - loss: 1.3118 - acc: 0.5240 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 3s - loss: 1.3002 - acc: 0.5284 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 3s - loss: 1.2891 - acc: 0.5332 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 3s - loss: 1.2782 - acc: 0.5386 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 3s - loss: 1.2673 - acc: 0.5425 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 3s - loss: 1.2568 - acc: 0.5485 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 3s - loss: 1.2460 - acc: 0.5537 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 3s - loss: 1.2351 - acc: 0.5580 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 3s - loss: 1.2241 - acc: 0.5639 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 3s - loss: 1.2128 - acc: 0.5696 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 3s - loss: 1.2014 - acc: 0.5750 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 3s - loss: 1.1896 - acc: 0.5805 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 3s - loss: 1.1775 - acc: 0.5861 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 3s - loss: 1.1651 - acc: 0.5921 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 3s - loss: 1.1524 - acc: 0.5967 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 3s - loss: 1.1394 - acc: 0.6035 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 1.1259 - acc: 0.6087 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 3s - loss: 1.1119 - acc: 0.6157 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 3s - loss: 1.0974 - acc: 0.6222 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 3s - loss: 1.0823 - acc: 0.6281 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 3s - loss: 1.0667 - acc: 0.6358 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 3s - loss: 1.0506 - acc: 0.6428 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 3s - loss: 1.0339 - acc: 0.6496 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 3s - loss: 1.0164 - acc: 0.6582 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.9988 - acc: 0.6662 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.9796 - acc: 0.6731 - val_loss: 7.5011e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.9603 - acc: 0.6818 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.9401 - acc: 0.6915 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.9192 - acc: 0.6998 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.8976 - acc: 0.7094 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.8752 - acc: 0.7197 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.8521 - acc: 0.7293 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.8283 - acc: 0.7380 - val_loss: 7.9616e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.8041 - acc: 0.7492 - val_loss: 9.8044e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.7785 - acc: 0.7586 - val_loss: 8.3553e-04 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.7535 - acc: 0.7702 - val_loss: 6.6589e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.7270 - acc: 0.7812 - val_loss: 9.1219e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.7003 - acc: 0.7918 - val_loss: 5.7296e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.6734 - acc: 0.8018 - val_loss: 3.4577e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.6463 - acc: 0.8141 - val_loss: 3.8613e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 4s - loss: 0.6191 - acc: 0.8246 - val_loss: 2.0786e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.5917 - acc: 0.8357 - val_loss: 3.7767e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.5643 - acc: 0.8465 - val_loss: 1.9737e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 4s - loss: 0.5368 - acc: 0.8570 - val_loss: 5.4237e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.5099 - acc: 0.8688 - val_loss: 2.5031e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.4831 - acc: 0.8791 - val_loss: 1.5111e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.4565 - acc: 0.8890 - val_loss: 1.3990e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.4303 - acc: 0.8997 - val_loss: 6.9919e-05 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.4048 - acc: 0.9095 - val_loss: 1.1862e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 4s - loss: 0.3800 - acc: 0.9192 - val_loss: 1.5916e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.3557 - acc: 0.9288 - val_loss: 5.3824e-05 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.3327 - acc: 0.9368 - val_loss: 5.2692e-05 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.3098 - acc: 0.9447 - val_loss: 9.9425e-05 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.2885 - acc: 0.9525 - val_loss: 3.5167e-05 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.2679 - acc: 0.9597 - val_loss: 2.5511e-05 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.2484 - acc: 0.9666 - val_loss: 5.5076e-05 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.2297 - acc: 0.9711 - val_loss: 8.7023e-06 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.2125 - acc: 0.9774 - val_loss: 7.8678e-06 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.1963 - acc: 0.9810 - val_loss: 1.7405e-05 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.1812 - acc: 0.9849 - val_loss: 7.5102e-06 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.1668 - acc: 0.9882 - val_loss: 7.6294e-06 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.1538 - acc: 0.9908 - val_loss: 8.9407e-06 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.1421 - acc: 0.9925 - val_loss: 5.0068e-06 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.1310 - acc: 0.9944 - val_loss: 8.3447e-06 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.1211 - acc: 0.9955 - val_loss: 3.2187e-06 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.1121 - acc: 0.9964 - val_loss: 1.0133e-05 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.1038 - acc: 0.9972 - val_loss: 7.9871e-06 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.0960 - acc: 0.9977 - val_loss: 2.5034e-06 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.0892 - acc: 0.9978 - val_loss: 5.7221e-06 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0831 - acc: 0.9984 - val_loss: 4.3511e-06 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.0773 - acc: 0.9986 - val_loss: 2.7418e-06 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.0724 - acc: 0.9987 - val_loss: 3.0994e-06 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 4s - loss: 0.0676 - acc: 0.9989 - val_loss: 1.1921e-06 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.0632 - acc: 0.9990 - val_loss: 2.6226e-06 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.0594 - acc: 0.9993 - val_loss: 2.3842e-06 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.0559 - acc: 0.9991 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.0527 - acc: 0.9994 - val_loss: 1.4901e-06 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.0498 - acc: 0.9994 - val_loss: 1.9074e-06 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.0470 - acc: 0.9996 - val_loss: 9.5367e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.0446 - acc: 0.9996 - val_loss: 2.3842e-06 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.0423 - acc: 0.9997 - val_loss: 2.2650e-06 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 4s - loss: 0.0402 - acc: 0.9997 - val_loss: 1.1921e-06 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.0382 - acc: 0.9997 - val_loss: 2.0266e-06 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0363 - acc: 0.9998 - val_loss: 1.0729e-06 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 4s - loss: 0.0348 - acc: 0.9998 - val_loss: 1.0729e-06 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 4s - loss: 0.0332 - acc: 0.9999 - val_loss: 5.3644e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 4s - loss: 0.0318 - acc: 0.9998 - val_loss: 8.3447e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 4s - loss: 0.0304 - acc: 0.9999 - val_loss: 7.1526e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 5s - loss: 0.0292 - acc: 0.9999 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 6s - loss: 0.0281 - acc: 0.9999 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 24s - loss: 1.7320 - acc: 0.4238 - val_loss: 0.0959 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 26s - loss: 1.4802 - acc: 0.4768 - val_loss: 0.0247 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 25s - loss: 1.4318 - acc: 0.4903 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 25s - loss: 1.4023 - acc: 0.4987 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 23s - loss: 1.3782 - acc: 0.5073 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 21s - loss: 1.3575 - acc: 0.5134 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 21s - loss: 1.3383 - acc: 0.5205 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 19s - loss: 1.3208 - acc: 0.5275 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 16s - loss: 1.3036 - acc: 0.5355 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 16s - loss: 1.2873 - acc: 0.5409 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 16s - loss: 1.2705 - acc: 0.5486 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 16s - loss: 1.2546 - acc: 0.5551 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 16s - loss: 1.2384 - acc: 0.5611 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 16s - loss: 1.2218 - acc: 0.5693 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 17s - loss: 1.2049 - acc: 0.5761 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 17s - loss: 1.1878 - acc: 0.5854 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 17s - loss: 1.1697 - acc: 0.5935 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 17s - loss: 1.1511 - acc: 0.6019 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 17s - loss: 1.1312 - acc: 0.6100 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 18s - loss: 1.1110 - acc: 0.6211 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 17s - loss: 1.0893 - acc: 0.6310 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 17s - loss: 1.0667 - acc: 0.6424 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 17s - loss: 1.0428 - acc: 0.6559 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 17s - loss: 1.0173 - acc: 0.6667 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 17s - loss: 0.9904 - acc: 0.6792 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 16s - loss: 0.9612 - acc: 0.6923 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 17s - loss: 0.9307 - acc: 0.7096 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 16s - loss: 0.8981 - acc: 0.7270 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 16s - loss: 0.8634 - acc: 0.7423 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 17s - loss: 0.8261 - acc: 0.7622 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 20s - loss: 0.7876 - acc: 0.7801 - val_loss: 9.3009e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 15s - loss: 0.7465 - acc: 0.8015 - val_loss: 7.9992e-04 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 15s - loss: 0.7035 - acc: 0.8214 - val_loss: 6.9499e-04 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 15s - loss: 0.6589 - acc: 0.8415 - val_loss: 5.3486e-04 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 16s - loss: 0.6135 - acc: 0.8608 - val_loss: 3.8118e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 16s - loss: 0.5667 - acc: 0.8811 - val_loss: 2.1824e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 16s - loss: 0.5196 - acc: 0.8989 - val_loss: 1.8902e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 17s - loss: 0.4734 - acc: 0.9180 - val_loss: 2.0727e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 17s - loss: 0.4282 - acc: 0.9337 - val_loss: 9.9127e-05 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 17s - loss: 0.3841 - acc: 0.9494 - val_loss: 1.7692e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 17s - loss: 0.3426 - acc: 0.9622 - val_loss: 1.8372e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 17s - loss: 0.3036 - acc: 0.9724 - val_loss: 8.6073e-05 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 17s - loss: 0.2678 - acc: 0.9804 - val_loss: 5.9547e-05 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 17s - loss: 0.2350 - acc: 0.9858 - val_loss: 6.9799e-05 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 17s - loss: 0.2061 - acc: 0.9904 - val_loss: 4.5301e-05 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 17s - loss: 0.1806 - acc: 0.9933 - val_loss: 2.8730e-05 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 17s - loss: 0.1584 - acc: 0.9950 - val_loss: 3.1651e-05 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 17s - loss: 0.1388 - acc: 0.9964 - val_loss: 4.5420e-05 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 18s - loss: 0.1224 - acc: 0.9970 - val_loss: 1.6928e-05 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 18s - loss: 0.1084 - acc: 0.9975 - val_loss: 1.6332e-05 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 18s - loss: 0.0965 - acc: 0.9978 - val_loss: 2.2710e-05 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 19s - loss: 0.0864 - acc: 0.9980 - val_loss: 9.7752e-06 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 19s - loss: 0.0776 - acc: 0.9984 - val_loss: 9.8348e-06 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 19s - loss: 0.0702 - acc: 0.9985 - val_loss: 8.4639e-06 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 19s - loss: 0.0637 - acc: 0.9988 - val_loss: 6.6161e-06 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 19s - loss: 0.0580 - acc: 0.9992 - val_loss: 6.5565e-06 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 19s - loss: 0.0533 - acc: 0.9991 - val_loss: 8.2851e-06 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 19s - loss: 0.0489 - acc: 0.9994 - val_loss: 6.9142e-06 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 21s - loss: 0.0452 - acc: 0.9995 - val_loss: 2.3842e-06 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 23s - loss: 0.0419 - acc: 0.9997 - val_loss: 3.9339e-06 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 18s - loss: 0.0390 - acc: 0.9997 - val_loss: 2.5034e-06 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 17s - loss: 0.0364 - acc: 0.9997 - val_loss: 3.0994e-06 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 17s - loss: 0.0340 - acc: 0.9998 - val_loss: 2.8610e-06 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 17s - loss: 0.0320 - acc: 0.9998 - val_loss: 1.0133e-06 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 16s - loss: 0.0301 - acc: 0.9998 - val_loss: 1.3113e-06 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 16s - loss: 0.0284 - acc: 0.9998 - val_loss: 1.7881e-06 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 17s - loss: 0.0268 - acc: 0.9999 - val_loss: 1.1921e-06 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 16s - loss: 0.0254 - acc: 0.9999 - val_loss: 1.5497e-06 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 15s - loss: 0.0241 - acc: 0.9999 - val_loss: 1.1325e-06 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 15s - loss: 0.0229 - acc: 0.9999 - val_loss: 1.0729e-06 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 15s - loss: 0.0218 - acc: 1.0000 - val_loss: 1.1921e-06 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 15s - loss: 0.0208 - acc: 0.9999 - val_loss: 6.5565e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 15s - loss: 0.0199 - acc: 1.0000 - val_loss: 7.1526e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 15s - loss: 0.0190 - acc: 1.0000 - val_loss: 8.3447e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 15s - loss: 0.0183 - acc: 1.0000 - val_loss: 5.3644e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 15s - loss: 0.0175 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 15s - loss: 0.0168 - acc: 1.0000 - val_loss: 6.5565e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 15s - loss: 0.0162 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 15s - loss: 0.0156 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 15s - loss: 0.0151 - acc: 1.0000 - val_loss: 3.5763e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 15s - loss: 0.0145 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 15s - loss: 0.0140 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 16s - loss: 0.0136 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 15s - loss: 0.0131 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 15s - loss: 0.0127 - acc: 1.0000 - val_loss: 1.7881e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 15s - loss: 0.0123 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 15s - loss: 0.0120 - acc: 1.0000 - val_loss: 1.7881e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 15s - loss: 0.0116 - acc: 1.0000 - val_loss: 1.7881e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 15s - loss: 0.0113 - acc: 1.0000 - val_loss: 1.7881e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 15s - loss: 0.0110 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 15s - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 15s - loss: 0.0104 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 15s - loss: 0.0101 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 14s - loss: 0.0098 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 15s - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 15s - loss: 0.0093 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 15s - loss: 0.0091 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 15s - loss: 0.0089 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 14s - loss: 0.0087 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 15s - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.2995 - acc: 0.1085 - val_loss: 2.3498 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.2798 - acc: 0.1204 - val_loss: 2.2066 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.2658 - acc: 0.1290 - val_loss: 2.0174 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.2528 - acc: 0.1389 - val_loss: 1.9067 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.2396 - acc: 0.1444 - val_loss: 1.8111 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.2278 - acc: 0.1465 - val_loss: 1.7474 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.2177 - acc: 0.1468 - val_loss: 1.5782 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.2087 - acc: 0.1467 - val_loss: 1.3954 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.1981 - acc: 0.1477 - val_loss: 1.1628 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2.1800 - acc: 0.1541 - val_loss: 0.9366 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 2.1566 - acc: 0.1811 - val_loss: 0.7683 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      " - 1s - loss: 2.1286 - acc: 0.1939 - val_loss: 0.6385 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.1046 - acc: 0.1965 - val_loss: 0.4896 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.0890 - acc: 0.1999 - val_loss: 0.4168 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.0783 - acc: 0.2031 - val_loss: 0.3612 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.0707 - acc: 0.2101 - val_loss: 0.3181 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.0649 - acc: 0.2139 - val_loss: 0.2752 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.0601 - acc: 0.2162 - val_loss: 0.2573 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.0563 - acc: 0.2183 - val_loss: 0.2229 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.0526 - acc: 0.2200 - val_loss: 0.2256 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.0496 - acc: 0.2216 - val_loss: 0.1909 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.0468 - acc: 0.2231 - val_loss: 0.1652 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.0442 - acc: 0.2244 - val_loss: 0.1578 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2.0421 - acc: 0.2253 - val_loss: 0.1431 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.0399 - acc: 0.2266 - val_loss: 0.1283 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.0382 - acc: 0.2276 - val_loss: 0.1173 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.0365 - acc: 0.2280 - val_loss: 0.1260 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.0349 - acc: 0.2285 - val_loss: 0.0966 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.0335 - acc: 0.2291 - val_loss: 0.1009 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.0322 - acc: 0.2303 - val_loss: 0.0836 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 2.0309 - acc: 0.2300 - val_loss: 0.0746 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 2.0297 - acc: 0.2309 - val_loss: 0.0752 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.0286 - acc: 0.2315 - val_loss: 0.0875 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.0275 - acc: 0.2314 - val_loss: 0.0757 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.0266 - acc: 0.2320 - val_loss: 0.0636 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.0255 - acc: 0.2325 - val_loss: 0.0631 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.0247 - acc: 0.2325 - val_loss: 0.0666 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.0239 - acc: 0.2333 - val_loss: 0.0634 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.0229 - acc: 0.2337 - val_loss: 0.0586 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.0222 - acc: 0.2336 - val_loss: 0.0609 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.0213 - acc: 0.2343 - val_loss: 0.0699 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.0207 - acc: 0.2341 - val_loss: 0.0522 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 2.0200 - acc: 0.2345 - val_loss: 0.0515 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2.0193 - acc: 0.2346 - val_loss: 0.0551 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2.0186 - acc: 0.2353 - val_loss: 0.0485 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2.0180 - acc: 0.2348 - val_loss: 0.0525 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 2.0173 - acc: 0.2355 - val_loss: 0.0500 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 2.0166 - acc: 0.2352 - val_loss: 0.0552 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 2.0162 - acc: 0.2354 - val_loss: 0.0477 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 2.0154 - acc: 0.2355 - val_loss: 0.0452 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 2.0150 - acc: 0.2359 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 2.0143 - acc: 0.2362 - val_loss: 0.0460 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 2.0139 - acc: 0.2363 - val_loss: 0.0456 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 2.0132 - acc: 0.2361 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 2.0128 - acc: 0.2363 - val_loss: 0.0415 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 2.0119 - acc: 0.2367 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 2.0094 - acc: 0.2378 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 2.0055 - acc: 0.2401 - val_loss: 0.0472 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 2.0018 - acc: 0.2409 - val_loss: 0.0384 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.9981 - acc: 0.2422 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.9945 - acc: 0.2439 - val_loss: 0.0325 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.9911 - acc: 0.2449 - val_loss: 0.0268 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.9879 - acc: 0.2455 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.9850 - acc: 0.2460 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.9822 - acc: 0.2470 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.9799 - acc: 0.2474 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.9776 - acc: 0.2481 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.9756 - acc: 0.2486 - val_loss: 0.0258 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.9736 - acc: 0.2492 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.9717 - acc: 0.2495 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.9700 - acc: 0.2498 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.9684 - acc: 0.2500 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.9668 - acc: 0.2505 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.9657 - acc: 0.2502 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.9643 - acc: 0.2511 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.9632 - acc: 0.2514 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.9621 - acc: 0.2518 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.9611 - acc: 0.2522 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.9601 - acc: 0.2525 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.9592 - acc: 0.2529 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.9582 - acc: 0.2532 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.9575 - acc: 0.2531 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.9567 - acc: 0.2535 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.9559 - acc: 0.2538 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.9552 - acc: 0.2539 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.9544 - acc: 0.2539 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.9537 - acc: 0.2542 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.9532 - acc: 0.2547 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.9524 - acc: 0.2550 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.9518 - acc: 0.2546 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.9513 - acc: 0.2552 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.9506 - acc: 0.2556 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.9500 - acc: 0.2557 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.9495 - acc: 0.2557 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.9491 - acc: 0.2557 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.9485 - acc: 0.2561 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 1.9481 - acc: 0.2564 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.9475 - acc: 0.2564 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.9470 - acc: 0.2566 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.9466 - acc: 0.2559 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.2883 - acc: 0.1349 - val_loss: 1.9770 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.2093 - acc: 0.1901 - val_loss: 1.2932 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.1362 - acc: 0.2148 - val_loss: 0.7086 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.0777 - acc: 0.2289 - val_loss: 0.3813 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.0386 - acc: 0.2369 - val_loss: 0.2270 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.0135 - acc: 0.2425 - val_loss: 0.1547 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.9966 - acc: 0.2467 - val_loss: 0.1093 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      " - 1s - loss: 1.9844 - acc: 0.2506 - val_loss: 0.0765 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.9749 - acc: 0.2531 - val_loss: 0.0587 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.9672 - acc: 0.2564 - val_loss: 0.0463 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.9606 - acc: 0.2590 - val_loss: 0.0346 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 1.9549 - acc: 0.2615 - val_loss: 0.0311 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 1.9497 - acc: 0.2638 - val_loss: 0.0252 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 1.9451 - acc: 0.2645 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 1.9409 - acc: 0.2676 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.9370 - acc: 0.2699 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 1.9334 - acc: 0.2715 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.9301 - acc: 0.2724 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.9268 - acc: 0.2739 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.9239 - acc: 0.2754 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.9210 - acc: 0.2769 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.9181 - acc: 0.2784 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.9155 - acc: 0.2791 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.9129 - acc: 0.2801 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.9104 - acc: 0.2826 - val_loss: 0.0163 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.9081 - acc: 0.2829 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.9057 - acc: 0.2838 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.9034 - acc: 0.2841 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.9012 - acc: 0.2870 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.8990 - acc: 0.2866 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.8967 - acc: 0.2876 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.8946 - acc: 0.2892 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.8924 - acc: 0.2897 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.8902 - acc: 0.2915 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.8882 - acc: 0.2924 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.8860 - acc: 0.2926 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.8839 - acc: 0.2934 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.8819 - acc: 0.2948 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.8797 - acc: 0.2958 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 1.8777 - acc: 0.2961 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.8757 - acc: 0.2980 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.8736 - acc: 0.2978 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.8716 - acc: 0.2994 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.8696 - acc: 0.3012 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.8675 - acc: 0.2993 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.8655 - acc: 0.3011 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.8635 - acc: 0.3005 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.8614 - acc: 0.3017 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.8596 - acc: 0.3014 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.8576 - acc: 0.3037 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.8555 - acc: 0.3054 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.8537 - acc: 0.3070 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.8517 - acc: 0.3065 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.8498 - acc: 0.3066 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.8480 - acc: 0.3083 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 1.8461 - acc: 0.3090 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.8443 - acc: 0.3094 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.8425 - acc: 0.3114 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 1.8408 - acc: 0.3111 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.8390 - acc: 0.3116 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.8374 - acc: 0.3132 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.8356 - acc: 0.3138 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.8341 - acc: 0.3135 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.8322 - acc: 0.3144 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.8307 - acc: 0.3160 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.8291 - acc: 0.3160 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.8275 - acc: 0.3161 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.8259 - acc: 0.3171 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.8244 - acc: 0.3170 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.8229 - acc: 0.3180 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.8213 - acc: 0.3180 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.8198 - acc: 0.3197 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.8183 - acc: 0.3198 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.8169 - acc: 0.3200 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.8155 - acc: 0.3209 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.8141 - acc: 0.3217 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.8126 - acc: 0.3217 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.8113 - acc: 0.3226 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.8100 - acc: 0.3229 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.8087 - acc: 0.3238 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.8074 - acc: 0.3242 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.8060 - acc: 0.3246 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.8047 - acc: 0.3241 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.8034 - acc: 0.3251 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.8021 - acc: 0.3259 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.8008 - acc: 0.3260 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.7996 - acc: 0.3266 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.7984 - acc: 0.3264 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.7971 - acc: 0.3275 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.7960 - acc: 0.3279 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.7947 - acc: 0.3290 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.7935 - acc: 0.3285 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.7923 - acc: 0.3299 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.7913 - acc: 0.3289 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.7901 - acc: 0.3303 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.7891 - acc: 0.3309 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 1.7881 - acc: 0.3312 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.7868 - acc: 0.3322 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.7858 - acc: 0.3319 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.7847 - acc: 0.3329 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.2566 - acc: 0.1721 - val_loss: 1.0709 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.1357 - acc: 0.2208 - val_loss: 0.4431 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.0689 - acc: 0.2377 - val_loss: 0.2173 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      " - 1s - loss: 2.0284 - acc: 0.2481 - val_loss: 0.1154 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 2s - loss: 2.0010 - acc: 0.2553 - val_loss: 0.0679 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.9814 - acc: 0.2597 - val_loss: 0.0427 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.9668 - acc: 0.2637 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.9553 - acc: 0.2673 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.9460 - acc: 0.2701 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.9380 - acc: 0.2734 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.9312 - acc: 0.2769 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 1.9249 - acc: 0.2809 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.9191 - acc: 0.2841 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 1.9136 - acc: 0.2871 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 1.9083 - acc: 0.2906 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.9032 - acc: 0.2939 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.8981 - acc: 0.2966 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.8931 - acc: 0.2996 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.8881 - acc: 0.3038 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.8832 - acc: 0.3067 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.8781 - acc: 0.3100 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.8731 - acc: 0.3127 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.8680 - acc: 0.3159 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.8628 - acc: 0.3190 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 2s - loss: 1.8576 - acc: 0.3224 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 2s - loss: 1.8522 - acc: 0.3246 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 2s - loss: 1.8467 - acc: 0.3279 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.8412 - acc: 0.3313 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.8355 - acc: 0.3341 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.8296 - acc: 0.3366 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 2s - loss: 1.8236 - acc: 0.3387 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 2s - loss: 1.8176 - acc: 0.3427 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 2s - loss: 1.8114 - acc: 0.3458 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 2s - loss: 1.8050 - acc: 0.3502 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 2s - loss: 1.7986 - acc: 0.3533 - val_loss: 8.9703e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 2s - loss: 1.7918 - acc: 0.3561 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 2s - loss: 1.7851 - acc: 0.3588 - val_loss: 7.4707e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 3s - loss: 1.7781 - acc: 0.3626 - val_loss: 8.4591e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 3s - loss: 1.7708 - acc: 0.3651 - val_loss: 6.4292e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 3s - loss: 1.7637 - acc: 0.3689 - val_loss: 6.5163e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 2s - loss: 1.7562 - acc: 0.3719 - val_loss: 6.0374e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 2s - loss: 1.7489 - acc: 0.3767 - val_loss: 5.4142e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 2s - loss: 1.7409 - acc: 0.3805 - val_loss: 4.2674e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 2s - loss: 1.7331 - acc: 0.3835 - val_loss: 4.4857e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 2s - loss: 1.7252 - acc: 0.3875 - val_loss: 3.6443e-04 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 2s - loss: 1.7170 - acc: 0.3914 - val_loss: 3.2943e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 2s - loss: 1.7089 - acc: 0.3940 - val_loss: 3.2049e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 2s - loss: 1.7006 - acc: 0.3976 - val_loss: 2.3046e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 2s - loss: 1.6922 - acc: 0.4015 - val_loss: 3.2848e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 2s - loss: 1.6837 - acc: 0.4048 - val_loss: 2.4256e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 3s - loss: 1.6754 - acc: 0.4088 - val_loss: 2.3362e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 2s - loss: 1.6666 - acc: 0.4127 - val_loss: 1.9749e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 2s - loss: 1.6580 - acc: 0.4154 - val_loss: 1.7889e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 2s - loss: 1.6493 - acc: 0.4189 - val_loss: 1.8008e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 2s - loss: 1.6405 - acc: 0.4233 - val_loss: 1.9224e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 2s - loss: 1.6316 - acc: 0.4264 - val_loss: 1.3662e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 2s - loss: 1.6228 - acc: 0.4305 - val_loss: 2.6510e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 2s - loss: 1.6142 - acc: 0.4346 - val_loss: 1.3346e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 2s - loss: 1.6053 - acc: 0.4368 - val_loss: 1.3853e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 2s - loss: 1.5968 - acc: 0.4412 - val_loss: 1.5916e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 2s - loss: 1.5878 - acc: 0.4444 - val_loss: 1.0658e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 2s - loss: 1.5791 - acc: 0.4478 - val_loss: 1.4211e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 3s - loss: 1.5706 - acc: 0.4513 - val_loss: 9.4537e-05 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 3s - loss: 1.5619 - acc: 0.4547 - val_loss: 8.5000e-05 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 2s - loss: 1.5529 - acc: 0.4578 - val_loss: 1.1171e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 2s - loss: 1.5445 - acc: 0.4607 - val_loss: 7.0813e-05 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 2s - loss: 1.5363 - acc: 0.4645 - val_loss: 7.4628e-05 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 2s - loss: 1.5279 - acc: 0.4674 - val_loss: 4.6254e-05 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.5195 - acc: 0.4703 - val_loss: 5.7043e-05 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 2s - loss: 1.5110 - acc: 0.4729 - val_loss: 5.3884e-05 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 2s - loss: 1.5029 - acc: 0.4767 - val_loss: 4.6970e-05 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 3s - loss: 1.4951 - acc: 0.4784 - val_loss: 4.5718e-05 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 3s - loss: 1.4872 - acc: 0.4812 - val_loss: 3.8327e-05 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 3s - loss: 1.4794 - acc: 0.4841 - val_loss: 3.4750e-05 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 2s - loss: 1.4716 - acc: 0.4867 - val_loss: 4.8042e-05 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 2s - loss: 1.4639 - acc: 0.4903 - val_loss: 3.1472e-05 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 2s - loss: 1.4566 - acc: 0.4928 - val_loss: 3.7909e-05 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 2s - loss: 1.4493 - acc: 0.4940 - val_loss: 2.5094e-05 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 2s - loss: 1.4422 - acc: 0.4981 - val_loss: 1.6451e-05 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 2s - loss: 1.4350 - acc: 0.4994 - val_loss: 3.7909e-05 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 2s - loss: 1.4280 - acc: 0.5023 - val_loss: 1.8299e-05 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 2s - loss: 1.4210 - acc: 0.5043 - val_loss: 1.2577e-05 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 2s - loss: 1.4142 - acc: 0.5078 - val_loss: 1.5974e-05 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 2s - loss: 1.4073 - acc: 0.5092 - val_loss: 2.6822e-05 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 2s - loss: 1.4010 - acc: 0.5104 - val_loss: 1.1504e-05 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 2s - loss: 1.3946 - acc: 0.5150 - val_loss: 1.3769e-05 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 2s - loss: 1.3881 - acc: 0.5171 - val_loss: 1.3590e-05 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 2s - loss: 1.3821 - acc: 0.5199 - val_loss: 7.3314e-06 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 2s - loss: 1.3755 - acc: 0.5212 - val_loss: 8.0467e-06 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 2s - loss: 1.3697 - acc: 0.5228 - val_loss: 2.2888e-05 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 2s - loss: 1.3639 - acc: 0.5247 - val_loss: 9.2984e-06 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 2s - loss: 1.3582 - acc: 0.5280 - val_loss: 6.8546e-06 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 2s - loss: 1.3523 - acc: 0.5296 - val_loss: 1.0371e-05 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 2s - loss: 1.3467 - acc: 0.5302 - val_loss: 1.0252e-05 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 2s - loss: 1.3413 - acc: 0.5326 - val_loss: 6.9142e-06 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 2s - loss: 1.3358 - acc: 0.5345 - val_loss: 2.3842e-06 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 2s - loss: 1.3305 - acc: 0.5376 - val_loss: 6.4969e-06 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      " - 2s - loss: 1.3252 - acc: 0.5388 - val_loss: 4.2915e-06 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 2s - loss: 1.3202 - acc: 0.5406 - val_loss: 3.0994e-06 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 2s - loss: 1.3150 - acc: 0.5424 - val_loss: 1.0014e-05 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 2.2221 - acc: 0.1927 - val_loss: 0.5713 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 3s - loss: 2.0934 - acc: 0.2394 - val_loss: 0.1860 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 3s - loss: 2.0408 - acc: 0.2513 - val_loss: 0.1027 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 3s - loss: 2.0116 - acc: 0.2587 - val_loss: 0.0613 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.9905 - acc: 0.2649 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.9737 - acc: 0.2701 - val_loss: 0.0425 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 3s - loss: 1.9597 - acc: 0.2746 - val_loss: 0.0303 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 3s - loss: 1.9472 - acc: 0.2802 - val_loss: 0.0247 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 3s - loss: 1.9359 - acc: 0.2849 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 3s - loss: 1.9256 - acc: 0.2885 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 3s - loss: 1.9158 - acc: 0.2938 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 3s - loss: 1.9064 - acc: 0.2985 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 3s - loss: 1.8973 - acc: 0.3031 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 3s - loss: 1.8882 - acc: 0.3087 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 3s - loss: 1.8790 - acc: 0.3143 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 3s - loss: 1.8700 - acc: 0.3175 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 3s - loss: 1.8608 - acc: 0.3222 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 3s - loss: 1.8514 - acc: 0.3279 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 3s - loss: 1.8416 - acc: 0.3337 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 3s - loss: 1.8312 - acc: 0.3388 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 3s - loss: 1.8208 - acc: 0.3452 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 3s - loss: 1.8100 - acc: 0.3505 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 3s - loss: 1.7985 - acc: 0.3562 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 3s - loss: 1.7865 - acc: 0.3622 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 3s - loss: 1.7743 - acc: 0.3674 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 3s - loss: 1.7609 - acc: 0.3741 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 3s - loss: 1.7472 - acc: 0.3804 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 3s - loss: 1.7328 - acc: 0.3872 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 3s - loss: 1.7174 - acc: 0.3955 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 3s - loss: 1.7012 - acc: 0.4023 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 3s - loss: 1.6839 - acc: 0.4116 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 3s - loss: 1.6659 - acc: 0.4193 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 3s - loss: 1.6467 - acc: 0.4279 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 3s - loss: 1.6263 - acc: 0.4384 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 3s - loss: 1.6049 - acc: 0.4478 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 3s - loss: 1.5819 - acc: 0.4585 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 3s - loss: 1.5580 - acc: 0.4694 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 3s - loss: 1.5328 - acc: 0.4810 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 3s - loss: 1.5062 - acc: 0.4934 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 3s - loss: 1.4783 - acc: 0.5047 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 3s - loss: 1.4489 - acc: 0.5159 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 3s - loss: 1.4182 - acc: 0.5285 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 3s - loss: 1.3862 - acc: 0.5420 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 3s - loss: 1.3533 - acc: 0.5561 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 3s - loss: 1.3192 - acc: 0.5694 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 3s - loss: 1.2837 - acc: 0.5834 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 3s - loss: 1.2474 - acc: 0.5965 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 3s - loss: 1.2102 - acc: 0.6114 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 3s - loss: 1.1720 - acc: 0.6262 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 3s - loss: 1.1336 - acc: 0.6420 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 3s - loss: 1.0947 - acc: 0.6558 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 3s - loss: 1.0550 - acc: 0.6702 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 3s - loss: 1.0150 - acc: 0.6874 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.9753 - acc: 0.7015 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.9353 - acc: 0.7171 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.8946 - acc: 0.7326 - val_loss: 6.5843e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.8548 - acc: 0.7466 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 4s - loss: 0.8156 - acc: 0.7616 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 4s - loss: 0.7762 - acc: 0.7773 - val_loss: 8.4704e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 4s - loss: 0.7371 - acc: 0.7921 - val_loss: 4.6061e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 4s - loss: 0.6990 - acc: 0.8077 - val_loss: 9.5479e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 4s - loss: 0.6608 - acc: 0.8217 - val_loss: 2.5419e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 4s - loss: 0.6234 - acc: 0.8365 - val_loss: 4.4863e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 4s - loss: 0.5876 - acc: 0.8490 - val_loss: 3.4171e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 4s - loss: 0.5517 - acc: 0.8648 - val_loss: 2.1442e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 4s - loss: 0.5170 - acc: 0.8791 - val_loss: 1.7579e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.4832 - acc: 0.8911 - val_loss: 2.1120e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 4s - loss: 0.4505 - acc: 0.9045 - val_loss: 4.5590e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.4187 - acc: 0.9172 - val_loss: 7.6893e-05 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 4s - loss: 0.3889 - acc: 0.9287 - val_loss: 3.8637e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.3596 - acc: 0.9389 - val_loss: 2.8253e-05 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 4s - loss: 0.3328 - acc: 0.9488 - val_loss: 1.0658e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 4s - loss: 0.3064 - acc: 0.9578 - val_loss: 7.0455e-05 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 4s - loss: 0.2821 - acc: 0.9667 - val_loss: 1.1785e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 4s - loss: 0.2591 - acc: 0.9737 - val_loss: 1.6749e-05 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 4s - loss: 0.2378 - acc: 0.9792 - val_loss: 1.3709e-05 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 4s - loss: 0.2179 - acc: 0.9851 - val_loss: 3.1114e-05 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 4s - loss: 0.1993 - acc: 0.9888 - val_loss: 2.5690e-05 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 4s - loss: 0.1828 - acc: 0.9917 - val_loss: 3.1829e-05 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 4s - loss: 0.1676 - acc: 0.9942 - val_loss: 8.9769e-05 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 4s - loss: 0.1532 - acc: 0.9960 - val_loss: 6.2587e-05 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 4s - loss: 0.1408 - acc: 0.9971 - val_loss: 9.6560e-06 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 4s - loss: 0.1294 - acc: 0.9980 - val_loss: 1.9826e-04 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 4s - loss: 0.1196 - acc: 0.9984 - val_loss: 2.8789e-05 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 4s - loss: 0.1101 - acc: 0.9989 - val_loss: 2.0743e-05 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 4s - loss: 0.1021 - acc: 0.9992 - val_loss: 5.0427e-05 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 4s - loss: 0.0948 - acc: 0.9992 - val_loss: 9.8944e-06 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.0880 - acc: 0.9995 - val_loss: 1.7762e-05 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 4s - loss: 0.0821 - acc: 0.9996 - val_loss: 9.5368e-06 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 4s - loss: 0.0767 - acc: 0.9996 - val_loss: 7.5102e-06 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 6s - loss: 0.0719 - acc: 0.9997 - val_loss: 6.9142e-06 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 5s - loss: 0.0675 - acc: 0.9997 - val_loss: 1.1623e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      " - 6s - loss: 0.0636 - acc: 0.9998 - val_loss: 5.2452e-06 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 4s - loss: 0.0600 - acc: 0.9998 - val_loss: 3.2783e-06 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 5s - loss: 0.0566 - acc: 0.9998 - val_loss: 4.2319e-06 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 5s - loss: 0.0538 - acc: 0.9998 - val_loss: 3.4571e-06 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 4s - loss: 0.0508 - acc: 0.9999 - val_loss: 3.4571e-06 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.0483 - acc: 0.9999 - val_loss: 8.2255e-06 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 4s - loss: 0.0460 - acc: 0.9999 - val_loss: 5.3644e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 4s - loss: 0.0439 - acc: 0.9999 - val_loss: 2.3246e-06 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 19s - loss: 2.1823 - acc: 0.2096 - val_loss: 0.4847 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 18s - loss: 2.0481 - acc: 0.2509 - val_loss: 0.1513 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 15s - loss: 2.0040 - acc: 0.2626 - val_loss: 0.0855 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 15s - loss: 1.9786 - acc: 0.2701 - val_loss: 0.0591 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 15s - loss: 1.9591 - acc: 0.2778 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 15s - loss: 1.9420 - acc: 0.2846 - val_loss: 0.0356 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 15s - loss: 1.9267 - acc: 0.2924 - val_loss: 0.0316 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 15s - loss: 1.9127 - acc: 0.2975 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 16s - loss: 1.8989 - acc: 0.3043 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 16s - loss: 1.8852 - acc: 0.3109 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 16s - loss: 1.8714 - acc: 0.3191 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 16s - loss: 1.8579 - acc: 0.3258 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 16s - loss: 1.8436 - acc: 0.3326 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 16s - loss: 1.8285 - acc: 0.3416 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 16s - loss: 1.8133 - acc: 0.3493 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 16s - loss: 1.7967 - acc: 0.3583 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 17s - loss: 1.7792 - acc: 0.3666 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 15s - loss: 1.7606 - acc: 0.3776 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 15s - loss: 1.7404 - acc: 0.3892 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 15s - loss: 1.7187 - acc: 0.3993 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 15s - loss: 1.6949 - acc: 0.4124 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 15s - loss: 1.6693 - acc: 0.4239 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 15s - loss: 1.6407 - acc: 0.4405 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 15s - loss: 1.6098 - acc: 0.4550 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 14s - loss: 1.5756 - acc: 0.4748 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 15s - loss: 1.5375 - acc: 0.4936 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 16s - loss: 1.4966 - acc: 0.5163 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 18s - loss: 1.4507 - acc: 0.5406 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 18s - loss: 1.4008 - acc: 0.5649 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 19s - loss: 1.3459 - acc: 0.5943 - val_loss: 7.8196e-04 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 17s - loss: 1.2862 - acc: 0.6234 - val_loss: 5.3020e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 19s - loss: 1.2217 - acc: 0.6517 - val_loss: 6.2873e-04 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 18s - loss: 1.1523 - acc: 0.6847 - val_loss: 4.5984e-04 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 20s - loss: 1.0794 - acc: 0.7163 - val_loss: 2.6730e-04 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 19s - loss: 1.0030 - acc: 0.7473 - val_loss: 1.8139e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 17s - loss: 0.9238 - acc: 0.7791 - val_loss: 1.6691e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 15s - loss: 0.8425 - acc: 0.8097 - val_loss: 7.9754e-05 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 16s - loss: 0.7611 - acc: 0.8405 - val_loss: 1.4330e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 16s - loss: 0.6808 - acc: 0.8692 - val_loss: 6.8905e-05 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 15s - loss: 0.6025 - acc: 0.8970 - val_loss: 1.0360e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 15s - loss: 0.5285 - acc: 0.9218 - val_loss: 9.0484e-05 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 15s - loss: 0.4596 - acc: 0.9438 - val_loss: 6.6461e-05 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 16s - loss: 0.3951 - acc: 0.9611 - val_loss: 6.7832e-05 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 15s - loss: 0.3382 - acc: 0.9740 - val_loss: 3.7611e-05 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 16s - loss: 0.2874 - acc: 0.9852 - val_loss: 1.8358e-05 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 16s - loss: 0.2437 - acc: 0.9913 - val_loss: 3.6419e-05 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 19s - loss: 0.2073 - acc: 0.9951 - val_loss: 2.1160e-05 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 20s - loss: 0.1762 - acc: 0.9973 - val_loss: 3.3677e-05 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 18s - loss: 0.1511 - acc: 0.9983 - val_loss: 1.6689e-05 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 20s - loss: 0.1305 - acc: 0.9986 - val_loss: 1.4126e-05 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 20s - loss: 0.1135 - acc: 0.9990 - val_loss: 4.1723e-06 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 20s - loss: 0.0997 - acc: 0.9994 - val_loss: 5.3048e-06 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 20s - loss: 0.0881 - acc: 0.9994 - val_loss: 5.1260e-06 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 19s - loss: 0.0787 - acc: 0.9997 - val_loss: 4.5896e-06 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 18s - loss: 0.0707 - acc: 0.9997 - val_loss: 4.0531e-06 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 16s - loss: 0.0639 - acc: 0.9999 - val_loss: 2.5630e-06 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 19s - loss: 0.0581 - acc: 0.9999 - val_loss: 2.6226e-06 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 15s - loss: 0.0532 - acc: 0.9999 - val_loss: 2.7418e-06 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 17s - loss: 0.0489 - acc: 0.9999 - val_loss: 2.3842e-06 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 15s - loss: 0.0452 - acc: 1.0000 - val_loss: 2.7418e-06 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 15s - loss: 0.0420 - acc: 1.0000 - val_loss: 1.5497e-06 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 14s - loss: 0.0391 - acc: 1.0000 - val_loss: 1.2517e-06 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 15s - loss: 0.0365 - acc: 1.0000 - val_loss: 1.3709e-06 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 16s - loss: 0.0343 - acc: 1.0000 - val_loss: 9.5367e-07 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 15s - loss: 0.0322 - acc: 1.0000 - val_loss: 9.5367e-07 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 14s - loss: 0.0303 - acc: 1.0000 - val_loss: 1.1921e-06 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 15s - loss: 0.0287 - acc: 1.0000 - val_loss: 8.3447e-07 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 14s - loss: 0.0272 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 15s - loss: 0.0258 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 14s - loss: 0.0246 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 17s - loss: 0.0234 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 17s - loss: 0.0223 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 16s - loss: 0.0214 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 16s - loss: 0.0204 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 18s - loss: 0.0196 - acc: 1.0000 - val_loss: 4.7684e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 27s - loss: 0.0188 - acc: 1.0000 - val_loss: 3.5763e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 28s - loss: 0.0181 - acc: 1.0000 - val_loss: 3.5763e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 31s - loss: 0.0174 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 23s - loss: 0.0168 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 15s - loss: 0.0162 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 15s - loss: 0.0156 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 19s - loss: 0.0151 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 15s - loss: 0.0146 - acc: 1.0000 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 14s - loss: 0.0142 - acc: 1.0000 - val_loss: 1.7881e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      " - 14s - loss: 0.0137 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 15s - loss: 0.0133 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 17s - loss: 0.0129 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 18s - loss: 0.0125 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 16s - loss: 0.0122 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 16s - loss: 0.0118 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 20s - loss: 0.0115 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 15s - loss: 0.0112 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 17s - loss: 0.0109 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 14s - loss: 0.0106 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 14s - loss: 0.0104 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 14s - loss: 0.0101 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 14s - loss: 0.0099 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 15s - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 16s - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 17s - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.3067 - acc: 0.1071 - val_loss: 2.2911 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.3007 - acc: 0.1151 - val_loss: 2.2142 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.2984 - acc: 0.1156 - val_loss: 2.1074 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.2965 - acc: 0.1167 - val_loss: 2.0057 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.2948 - acc: 0.1180 - val_loss: 1.9154 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.2932 - acc: 0.1186 - val_loss: 1.8236 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.2917 - acc: 0.1191 - val_loss: 1.7201 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.2902 - acc: 0.1196 - val_loss: 1.6321 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.2888 - acc: 0.1199 - val_loss: 1.5376 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2.2875 - acc: 0.1205 - val_loss: 1.4467 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 2.2862 - acc: 0.1205 - val_loss: 1.3248 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.2849 - acc: 0.1208 - val_loss: 1.2276 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.2836 - acc: 0.1213 - val_loss: 1.1301 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.2823 - acc: 0.1213 - val_loss: 1.0237 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.2810 - acc: 0.1217 - val_loss: 0.9567 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.2798 - acc: 0.1222 - val_loss: 0.8556 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.2786 - acc: 0.1225 - val_loss: 0.7722 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.2775 - acc: 0.1225 - val_loss: 0.7056 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.2764 - acc: 0.1228 - val_loss: 0.6537 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.2753 - acc: 0.1233 - val_loss: 0.6109 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.2743 - acc: 0.1236 - val_loss: 0.5754 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.2733 - acc: 0.1240 - val_loss: 0.5391 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.2723 - acc: 0.1241 - val_loss: 0.5183 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2.2713 - acc: 0.1245 - val_loss: 0.4930 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.2704 - acc: 0.1250 - val_loss: 0.4795 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.2695 - acc: 0.1254 - val_loss: 0.4673 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.2685 - acc: 0.1255 - val_loss: 0.4533 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.2676 - acc: 0.1258 - val_loss: 0.4459 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.2667 - acc: 0.1265 - val_loss: 0.4301 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.2658 - acc: 0.1264 - val_loss: 0.4294 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 2.2649 - acc: 0.1263 - val_loss: 0.4220 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 2.2641 - acc: 0.1274 - val_loss: 0.4224 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.2632 - acc: 0.1273 - val_loss: 0.4115 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.2623 - acc: 0.1278 - val_loss: 0.4143 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.2615 - acc: 0.1277 - val_loss: 0.4083 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.2607 - acc: 0.1286 - val_loss: 0.4005 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.2598 - acc: 0.1287 - val_loss: 0.3955 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.2590 - acc: 0.1292 - val_loss: 0.3904 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.2582 - acc: 0.1299 - val_loss: 0.3886 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.2573 - acc: 0.1302 - val_loss: 0.3891 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.2565 - acc: 0.1313 - val_loss: 0.3807 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.2557 - acc: 0.1314 - val_loss: 0.3698 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 2.2550 - acc: 0.1309 - val_loss: 0.3701 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2.2542 - acc: 0.1322 - val_loss: 0.3629 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2.2534 - acc: 0.1327 - val_loss: 0.3683 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2.2527 - acc: 0.1334 - val_loss: 0.3634 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 2.2519 - acc: 0.1331 - val_loss: 0.3618 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 2.2512 - acc: 0.1337 - val_loss: 0.3504 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 2.2505 - acc: 0.1343 - val_loss: 0.3395 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 2.2497 - acc: 0.1368 - val_loss: 0.3439 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 2.2491 - acc: 0.1374 - val_loss: 0.3286 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 2.2484 - acc: 0.1385 - val_loss: 0.3311 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 2s - loss: 2.2477 - acc: 0.1385 - val_loss: 0.3205 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 2s - loss: 2.2470 - acc: 0.1391 - val_loss: 0.3246 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 2.2464 - acc: 0.1395 - val_loss: 0.3144 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 2.2457 - acc: 0.1400 - val_loss: 0.3021 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 2.2451 - acc: 0.1404 - val_loss: 0.3046 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 2.2445 - acc: 0.1411 - val_loss: 0.3054 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 2.2439 - acc: 0.1401 - val_loss: 0.2953 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 2.2433 - acc: 0.1415 - val_loss: 0.2928 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 2.2427 - acc: 0.1418 - val_loss: 0.2928 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 2.2421 - acc: 0.1417 - val_loss: 0.2856 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 2s - loss: 2.2416 - acc: 0.1424 - val_loss: 0.2795 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 2s - loss: 2.2410 - acc: 0.1426 - val_loss: 0.2782 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 2s - loss: 2.2405 - acc: 0.1427 - val_loss: 0.2737 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 2.2399 - acc: 0.1429 - val_loss: 0.2707 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 2s - loss: 2.2394 - acc: 0.1428 - val_loss: 0.2642 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 2s - loss: 2.2389 - acc: 0.1437 - val_loss: 0.2643 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 2.2384 - acc: 0.1434 - val_loss: 0.2559 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 2.2378 - acc: 0.1432 - val_loss: 0.2615 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 2.2374 - acc: 0.1432 - val_loss: 0.2569 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 2.2369 - acc: 0.1438 - val_loss: 0.2558 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 2.2364 - acc: 0.1436 - val_loss: 0.2479 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 2.2360 - acc: 0.1441 - val_loss: 0.2386 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 2.2355 - acc: 0.1451 - val_loss: 0.2465 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 2.2351 - acc: 0.1447 - val_loss: 0.2410 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 2.2345 - acc: 0.1450 - val_loss: 0.2401 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 2.2342 - acc: 0.1452 - val_loss: 0.2368 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 2.2337 - acc: 0.1449 - val_loss: 0.2363 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      " - 1s - loss: 2.2334 - acc: 0.1450 - val_loss: 0.2288 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 2.2329 - acc: 0.1457 - val_loss: 0.2328 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 2.2326 - acc: 0.1465 - val_loss: 0.2279 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 2.2322 - acc: 0.1461 - val_loss: 0.2298 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 2.2318 - acc: 0.1464 - val_loss: 0.2245 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 2.2314 - acc: 0.1467 - val_loss: 0.2234 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 2.2310 - acc: 0.1471 - val_loss: 0.2241 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 2.2307 - acc: 0.1466 - val_loss: 0.2211 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 2.2303 - acc: 0.1471 - val_loss: 0.2232 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 2.2300 - acc: 0.1468 - val_loss: 0.2135 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 2.2295 - acc: 0.1472 - val_loss: 0.2155 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 2.2292 - acc: 0.1469 - val_loss: 0.2157 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 2.2288 - acc: 0.1476 - val_loss: 0.2104 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 2.2285 - acc: 0.1476 - val_loss: 0.2173 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 2.2281 - acc: 0.1474 - val_loss: 0.2139 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 2.2278 - acc: 0.1477 - val_loss: 0.2091 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 2.2275 - acc: 0.1477 - val_loss: 0.2120 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 2.2271 - acc: 0.1480 - val_loss: 0.2147 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 2.2268 - acc: 0.1483 - val_loss: 0.2101 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 2.2265 - acc: 0.1481 - val_loss: 0.2088 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 2.2262 - acc: 0.1479 - val_loss: 0.2005 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.3174 - acc: 0.1033 - val_loss: 2.2591 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.3034 - acc: 0.1099 - val_loss: 2.2311 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.2996 - acc: 0.1135 - val_loss: 2.2107 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.2969 - acc: 0.1159 - val_loss: 2.1809 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.2943 - acc: 0.1191 - val_loss: 2.1578 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 2s - loss: 2.2918 - acc: 0.1215 - val_loss: 2.1226 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.2891 - acc: 0.1243 - val_loss: 2.0313 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 2s - loss: 2.2863 - acc: 0.1270 - val_loss: 1.9462 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 2s - loss: 2.2834 - acc: 0.1291 - val_loss: 1.8641 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 2s - loss: 2.2805 - acc: 0.1315 - val_loss: 1.7608 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 2.2775 - acc: 0.1324 - val_loss: 1.6666 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.2746 - acc: 0.1348 - val_loss: 1.5510 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.2716 - acc: 0.1361 - val_loss: 1.4430 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 2s - loss: 2.2685 - acc: 0.1380 - val_loss: 1.3277 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.2654 - acc: 0.1400 - val_loss: 1.2161 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.2621 - acc: 0.1417 - val_loss: 1.1137 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.2590 - acc: 0.1427 - val_loss: 1.0035 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.2558 - acc: 0.1431 - val_loss: 0.9188 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.2525 - acc: 0.1457 - val_loss: 0.8483 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.2492 - acc: 0.1476 - val_loss: 0.7638 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.2461 - acc: 0.1487 - val_loss: 0.6961 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.2428 - acc: 0.1515 - val_loss: 0.6369 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.2396 - acc: 0.1528 - val_loss: 0.5821 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2.2366 - acc: 0.1548 - val_loss: 0.5400 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.2337 - acc: 0.1573 - val_loss: 0.4959 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.2309 - acc: 0.1583 - val_loss: 0.4509 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.2282 - acc: 0.1593 - val_loss: 0.4077 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.2256 - acc: 0.1605 - val_loss: 0.3872 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.2231 - acc: 0.1618 - val_loss: 0.3573 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.2207 - acc: 0.1636 - val_loss: 0.3229 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 2.2183 - acc: 0.1658 - val_loss: 0.2865 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 2.2159 - acc: 0.1666 - val_loss: 0.2701 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.2137 - acc: 0.1677 - val_loss: 0.2550 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.2114 - acc: 0.1694 - val_loss: 0.2357 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.2092 - acc: 0.1706 - val_loss: 0.2127 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.2069 - acc: 0.1726 - val_loss: 0.2105 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.2047 - acc: 0.1737 - val_loss: 0.1862 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.2025 - acc: 0.1751 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.2004 - acc: 0.1758 - val_loss: 0.1559 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.1982 - acc: 0.1771 - val_loss: 0.1474 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.1960 - acc: 0.1786 - val_loss: 0.1387 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.1939 - acc: 0.1792 - val_loss: 0.1232 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 1s - loss: 2.1917 - acc: 0.1816 - val_loss: 0.1180 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2.1897 - acc: 0.1816 - val_loss: 0.1051 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2.1875 - acc: 0.1829 - val_loss: 0.0999 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2.1854 - acc: 0.1839 - val_loss: 0.0914 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 1s - loss: 2.1834 - acc: 0.1857 - val_loss: 0.0853 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 1s - loss: 2.1813 - acc: 0.1876 - val_loss: 0.0784 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 1s - loss: 2.1793 - acc: 0.1882 - val_loss: 0.0740 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 1s - loss: 2.1772 - acc: 0.1888 - val_loss: 0.0732 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 1s - loss: 2.1752 - acc: 0.1894 - val_loss: 0.0671 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 1s - loss: 2.1732 - acc: 0.1918 - val_loss: 0.0609 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 1s - loss: 2.1712 - acc: 0.1917 - val_loss: 0.0595 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 1s - loss: 2.1692 - acc: 0.1943 - val_loss: 0.0561 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 2.1673 - acc: 0.1946 - val_loss: 0.0535 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 1s - loss: 2.1654 - acc: 0.1956 - val_loss: 0.0515 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 2.1634 - acc: 0.1960 - val_loss: 0.0517 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 2.1616 - acc: 0.1976 - val_loss: 0.0462 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 2.1597 - acc: 0.1978 - val_loss: 0.0415 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 2.1578 - acc: 0.1990 - val_loss: 0.0433 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 2.1559 - acc: 0.2010 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 2.1541 - acc: 0.2007 - val_loss: 0.0419 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 1s - loss: 2.1523 - acc: 0.2018 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 1s - loss: 2.1505 - acc: 0.2031 - val_loss: 0.0367 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 1s - loss: 2.1487 - acc: 0.2045 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 1s - loss: 2.1471 - acc: 0.2047 - val_loss: 0.0364 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 1s - loss: 2.1453 - acc: 0.2051 - val_loss: 0.0356 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 1s - loss: 2.1436 - acc: 0.2065 - val_loss: 0.0339 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 2.1419 - acc: 0.2060 - val_loss: 0.0308 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 1s - loss: 2.1402 - acc: 0.2074 - val_loss: 0.0337 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 1s - loss: 2.1385 - acc: 0.2077 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 1s - loss: 2.1369 - acc: 0.2079 - val_loss: 0.0292 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 2.1353 - acc: 0.2087 - val_loss: 0.0298 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 2.1337 - acc: 0.2095 - val_loss: 0.0309 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 2.1323 - acc: 0.2103 - val_loss: 0.0279 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      " - 1s - loss: 2.1307 - acc: 0.2105 - val_loss: 0.0283 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 2.1291 - acc: 0.2121 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 2.1277 - acc: 0.2126 - val_loss: 0.0279 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 2.1263 - acc: 0.2139 - val_loss: 0.0260 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 2.1248 - acc: 0.2139 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 2s - loss: 2.1234 - acc: 0.2137 - val_loss: 0.0272 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 2s - loss: 2.1219 - acc: 0.2143 - val_loss: 0.0263 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 2.1205 - acc: 0.2157 - val_loss: 0.0272 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 2.1192 - acc: 0.2161 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 2.1178 - acc: 0.2163 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 2.1166 - acc: 0.2174 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 2.1153 - acc: 0.2178 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 2.1139 - acc: 0.2179 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 2.1127 - acc: 0.2187 - val_loss: 0.0263 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 2.1115 - acc: 0.2182 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 2.1102 - acc: 0.2195 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 2.1091 - acc: 0.2190 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 2.1079 - acc: 0.2208 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 2.1066 - acc: 0.2203 - val_loss: 0.0243 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 2.1055 - acc: 0.2199 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 2.1042 - acc: 0.2217 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 2.1031 - acc: 0.2225 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 2.1020 - acc: 0.2234 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 2.1009 - acc: 0.2237 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 2.0998 - acc: 0.2234 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.3370 - acc: 0.1060 - val_loss: 1.9664 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.3117 - acc: 0.1152 - val_loss: 1.8730 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.3011 - acc: 0.1214 - val_loss: 1.7397 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.2935 - acc: 0.1259 - val_loss: 1.6107 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.2869 - acc: 0.1300 - val_loss: 1.4432 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 2s - loss: 2.2807 - acc: 0.1343 - val_loss: 1.2862 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.2748 - acc: 0.1365 - val_loss: 1.1405 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.2691 - acc: 0.1387 - val_loss: 0.9686 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.2636 - acc: 0.1415 - val_loss: 0.8264 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2.2584 - acc: 0.1441 - val_loss: 0.6846 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 1s - loss: 2.2534 - acc: 0.1461 - val_loss: 0.5934 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.2485 - acc: 0.1500 - val_loss: 0.4873 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.2439 - acc: 0.1533 - val_loss: 0.4191 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.2394 - acc: 0.1554 - val_loss: 0.3611 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.2350 - acc: 0.1585 - val_loss: 0.2885 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.2307 - acc: 0.1616 - val_loss: 0.2383 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.2264 - acc: 0.1637 - val_loss: 0.2192 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.2221 - acc: 0.1674 - val_loss: 0.1899 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.2179 - acc: 0.1712 - val_loss: 0.1620 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.2136 - acc: 0.1732 - val_loss: 0.1366 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.2093 - acc: 0.1764 - val_loss: 0.1149 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.2050 - acc: 0.1798 - val_loss: 0.1065 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.2005 - acc: 0.1831 - val_loss: 0.0907 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2.1960 - acc: 0.1848 - val_loss: 0.0786 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.1914 - acc: 0.1879 - val_loss: 0.0704 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.1867 - acc: 0.1912 - val_loss: 0.0598 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.1818 - acc: 0.1936 - val_loss: 0.0568 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.1769 - acc: 0.1983 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.1719 - acc: 0.2002 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.1667 - acc: 0.2044 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 1s - loss: 2.1614 - acc: 0.2076 - val_loss: 0.0358 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 1s - loss: 2.1558 - acc: 0.2097 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.1502 - acc: 0.2138 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.1444 - acc: 0.2170 - val_loss: 0.0265 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.1385 - acc: 0.2204 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.1324 - acc: 0.2230 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 2s - loss: 2.1262 - acc: 0.2255 - val_loss: 0.0226 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 2s - loss: 2.1199 - acc: 0.2291 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 2s - loss: 2.1133 - acc: 0.2336 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 2s - loss: 2.1065 - acc: 0.2370 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 2s - loss: 2.0997 - acc: 0.2408 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 2s - loss: 2.0927 - acc: 0.2438 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 2s - loss: 2.0856 - acc: 0.2467 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 2s - loss: 2.0783 - acc: 0.2511 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 2s - loss: 2.0708 - acc: 0.2549 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 2s - loss: 2.0631 - acc: 0.2585 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 2s - loss: 2.0554 - acc: 0.2619 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 2s - loss: 2.0474 - acc: 0.2659 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 3s - loss: 2.0394 - acc: 0.2697 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 2s - loss: 2.0312 - acc: 0.2740 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 2s - loss: 2.0230 - acc: 0.2773 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 2s - loss: 2.0143 - acc: 0.2813 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 2s - loss: 2.0058 - acc: 0.2849 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 2s - loss: 1.9970 - acc: 0.2888 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 2s - loss: 1.9883 - acc: 0.2926 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 2s - loss: 1.9795 - acc: 0.2963 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 2s - loss: 1.9708 - acc: 0.3004 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.9619 - acc: 0.3034 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 1.9528 - acc: 0.3072 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.9438 - acc: 0.3123 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.9347 - acc: 0.3156 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.9258 - acc: 0.3191 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 2s - loss: 1.9167 - acc: 0.3215 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 2s - loss: 1.9076 - acc: 0.3262 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 2s - loss: 1.8986 - acc: 0.3300 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 2s - loss: 1.8897 - acc: 0.3335 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 2s - loss: 1.8809 - acc: 0.3369 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 2s - loss: 1.8723 - acc: 0.3401 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 2s - loss: 1.8636 - acc: 0.3433 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 2s - loss: 1.8549 - acc: 0.3458 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 2s - loss: 1.8467 - acc: 0.3491 - val_loss: 0.0062 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      " - 1s - loss: 1.8382 - acc: 0.3540 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.8303 - acc: 0.3555 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.8221 - acc: 0.3595 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.8145 - acc: 0.3620 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.8065 - acc: 0.3655 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.7990 - acc: 0.3686 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.7913 - acc: 0.3710 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 2s - loss: 1.7842 - acc: 0.3743 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.7768 - acc: 0.3766 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.7698 - acc: 0.3791 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.7628 - acc: 0.3813 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.7563 - acc: 0.3838 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.7496 - acc: 0.3862 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.7431 - acc: 0.3884 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.7370 - acc: 0.3911 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.7310 - acc: 0.3936 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.7247 - acc: 0.3954 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.7188 - acc: 0.3981 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.7132 - acc: 0.3996 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.7077 - acc: 0.4013 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.7019 - acc: 0.4032 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.6959 - acc: 0.4062 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.6905 - acc: 0.4081 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.6855 - acc: 0.4100 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.6803 - acc: 0.4106 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 1.6756 - acc: 0.4112 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.6704 - acc: 0.4146 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 2s - loss: 1.6654 - acc: 0.4168 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 2s - loss: 1.6610 - acc: 0.4173 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 2.3315 - acc: 0.1060 - val_loss: 2.1488 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 3s - loss: 2.3075 - acc: 0.1244 - val_loss: 1.9013 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 3s - loss: 2.2928 - acc: 0.1325 - val_loss: 1.7214 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 3s - loss: 2.2813 - acc: 0.1405 - val_loss: 1.4542 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 3s - loss: 2.2719 - acc: 0.1451 - val_loss: 1.3198 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 3s - loss: 2.2631 - acc: 0.1495 - val_loss: 1.1300 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 3s - loss: 2.2552 - acc: 0.1547 - val_loss: 0.9639 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 3s - loss: 2.2477 - acc: 0.1582 - val_loss: 0.8513 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 3s - loss: 2.2403 - acc: 0.1628 - val_loss: 0.7216 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 3s - loss: 2.2335 - acc: 0.1657 - val_loss: 0.6165 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 3s - loss: 2.2265 - acc: 0.1703 - val_loss: 0.5457 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 3s - loss: 2.2199 - acc: 0.1745 - val_loss: 0.4629 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 3s - loss: 2.2132 - acc: 0.1786 - val_loss: 0.4265 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 3s - loss: 2.2065 - acc: 0.1825 - val_loss: 0.3604 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 3s - loss: 2.1996 - acc: 0.1861 - val_loss: 0.3288 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 3s - loss: 2.1924 - acc: 0.1912 - val_loss: 0.2885 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 3s - loss: 2.1854 - acc: 0.1944 - val_loss: 0.2639 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 3s - loss: 2.1781 - acc: 0.1997 - val_loss: 0.2120 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 3s - loss: 2.1704 - acc: 0.2043 - val_loss: 0.1766 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 3s - loss: 2.1625 - acc: 0.2098 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 3s - loss: 2.1542 - acc: 0.2136 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 3s - loss: 2.1458 - acc: 0.2190 - val_loss: 0.1364 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 3s - loss: 2.1368 - acc: 0.2231 - val_loss: 0.1160 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 3s - loss: 2.1273 - acc: 0.2291 - val_loss: 0.1066 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 4s - loss: 2.1177 - acc: 0.2331 - val_loss: 0.0944 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 3s - loss: 2.1072 - acc: 0.2396 - val_loss: 0.0866 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 3s - loss: 2.0965 - acc: 0.2453 - val_loss: 0.0706 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 3s - loss: 2.0851 - acc: 0.2511 - val_loss: 0.0663 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 3s - loss: 2.0730 - acc: 0.2580 - val_loss: 0.0566 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 3s - loss: 2.0600 - acc: 0.2653 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 3s - loss: 2.0467 - acc: 0.2705 - val_loss: 0.0462 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 3s - loss: 2.0321 - acc: 0.2782 - val_loss: 0.0414 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 4s - loss: 2.0168 - acc: 0.2864 - val_loss: 0.0335 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 4s - loss: 2.0002 - acc: 0.2951 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 4s - loss: 1.9826 - acc: 0.3043 - val_loss: 0.0278 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 3s - loss: 1.9642 - acc: 0.3132 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 3s - loss: 1.9441 - acc: 0.3216 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 3s - loss: 1.9229 - acc: 0.3327 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 3s - loss: 1.9002 - acc: 0.3425 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 3s - loss: 1.8760 - acc: 0.3537 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 3s - loss: 1.8505 - acc: 0.3656 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 3s - loss: 1.8229 - acc: 0.3777 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 3s - loss: 1.7939 - acc: 0.3899 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 3s - loss: 1.7629 - acc: 0.4022 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 3s - loss: 1.7307 - acc: 0.4157 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 3s - loss: 1.6965 - acc: 0.4309 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 3s - loss: 1.6610 - acc: 0.4448 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 3s - loss: 1.6246 - acc: 0.4581 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 3s - loss: 1.5862 - acc: 0.4736 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 4s - loss: 1.5470 - acc: 0.4886 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 3s - loss: 1.5073 - acc: 0.5036 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 3s - loss: 1.4660 - acc: 0.5185 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 3s - loss: 1.4235 - acc: 0.5358 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 3s - loss: 1.3807 - acc: 0.5511 - val_loss: 7.7099e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 3s - loss: 1.3370 - acc: 0.5669 - val_loss: 5.9467e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 3s - loss: 1.2937 - acc: 0.5820 - val_loss: 5.4541e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 3s - loss: 1.2498 - acc: 0.5994 - val_loss: 5.2525e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 3s - loss: 1.2047 - acc: 0.6176 - val_loss: 2.1776e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 3s - loss: 1.1605 - acc: 0.6317 - val_loss: 1.7960e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 3s - loss: 1.1153 - acc: 0.6514 - val_loss: 4.2287e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 3s - loss: 1.0721 - acc: 0.6671 - val_loss: 9.9902e-05 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 3s - loss: 1.0272 - acc: 0.6822 - val_loss: 2.2611e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.9843 - acc: 0.6976 - val_loss: 9.7995e-05 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.9395 - acc: 0.7154 - val_loss: 1.1343e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.8971 - acc: 0.7328 - val_loss: 3.4333e-05 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.8543 - acc: 0.7493 - val_loss: 1.0902e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.8122 - acc: 0.7654 - val_loss: 1.5736e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      " - 3s - loss: 0.7714 - acc: 0.7793 - val_loss: 4.1247e-05 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.7300 - acc: 0.7976 - val_loss: 2.8730e-05 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.6903 - acc: 0.8125 - val_loss: 4.1128e-05 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.6519 - acc: 0.8275 - val_loss: 1.4544e-05 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.6135 - acc: 0.8423 - val_loss: 1.5259e-05 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.5759 - acc: 0.8579 - val_loss: 1.1087e-05 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.5389 - acc: 0.8723 - val_loss: 3.3379e-06 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.5040 - acc: 0.8871 - val_loss: 1.1921e-05 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.4696 - acc: 0.8998 - val_loss: 1.3828e-05 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.4375 - acc: 0.9123 - val_loss: 2.7418e-06 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.4053 - acc: 0.9249 - val_loss: 2.9802e-06 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.3754 - acc: 0.9367 - val_loss: 1.2517e-06 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.3465 - acc: 0.9468 - val_loss: 1.5497e-06 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.3187 - acc: 0.9571 - val_loss: 3.0994e-06 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.2926 - acc: 0.9658 - val_loss: 3.5763e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.2687 - acc: 0.9732 - val_loss: 7.1526e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.2459 - acc: 0.9793 - val_loss: 6.5565e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.2251 - acc: 0.9843 - val_loss: 2.9802e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.2058 - acc: 0.9892 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 4s - loss: 0.1885 - acc: 0.9926 - val_loss: 2.3842e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.1724 - acc: 0.9951 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.1579 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.1449 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.1330 - acc: 0.9988 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.1224 - acc: 0.9993 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.1131 - acc: 0.9996 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.1047 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.0971 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.0905 - acc: 0.9999 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.0845 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.0791 - acc: 0.9999 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.0742 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.0698 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 2.3210 - acc: 0.1090 - val_loss: 1.6267 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      " - 13s - loss: 2.2925 - acc: 0.1325 - val_loss: 1.1998 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      " - 13s - loss: 2.2724 - acc: 0.1443 - val_loss: 0.9799 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      " - 14s - loss: 2.2565 - acc: 0.1541 - val_loss: 0.7400 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      " - 13s - loss: 2.2434 - acc: 0.1607 - val_loss: 0.6485 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      " - 13s - loss: 2.2314 - acc: 0.1709 - val_loss: 0.4818 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      " - 13s - loss: 2.2204 - acc: 0.1770 - val_loss: 0.4009 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      " - 13s - loss: 2.2100 - acc: 0.1833 - val_loss: 0.3631 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      " - 13s - loss: 2.1999 - acc: 0.1910 - val_loss: 0.2731 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      " - 13s - loss: 2.1900 - acc: 0.1962 - val_loss: 0.2394 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      " - 13s - loss: 2.1800 - acc: 0.2028 - val_loss: 0.1968 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      " - 13s - loss: 2.1694 - acc: 0.2093 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      " - 14s - loss: 2.1589 - acc: 0.2155 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      " - 14s - loss: 2.1479 - acc: 0.2204 - val_loss: 0.1249 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      " - 14s - loss: 2.1360 - acc: 0.2276 - val_loss: 0.1143 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      " - 15s - loss: 2.1240 - acc: 0.2346 - val_loss: 0.1011 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      " - 14s - loss: 2.1109 - acc: 0.2421 - val_loss: 0.0903 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      " - 14s - loss: 2.0966 - acc: 0.2514 - val_loss: 0.0723 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      " - 14s - loss: 2.0814 - acc: 0.2596 - val_loss: 0.0735 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      " - 14s - loss: 2.0650 - acc: 0.2685 - val_loss: 0.0771 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      " - 14s - loss: 2.0470 - acc: 0.2772 - val_loss: 0.0662 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 14s - loss: 2.0271 - acc: 0.2912 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 14s - loss: 2.0056 - acc: 0.3017 - val_loss: 0.0472 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 14s - loss: 1.9810 - acc: 0.3159 - val_loss: 0.0386 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 14s - loss: 1.9543 - acc: 0.3293 - val_loss: 0.0339 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 14s - loss: 1.9244 - acc: 0.3450 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 14s - loss: 1.8903 - acc: 0.3634 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 14s - loss: 1.8527 - acc: 0.3835 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      " - 15s - loss: 1.8097 - acc: 0.4056 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      " - 15s - loss: 1.7625 - acc: 0.4293 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      " - 15s - loss: 1.7090 - acc: 0.4606 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      " - 15s - loss: 1.6497 - acc: 0.4878 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 15s - loss: 1.5835 - acc: 0.5210 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 15s - loss: 1.5112 - acc: 0.5537 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 17s - loss: 1.4338 - acc: 0.5880 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 15s - loss: 1.3496 - acc: 0.6274 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 15s - loss: 1.2591 - acc: 0.6646 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 15s - loss: 1.1654 - acc: 0.7006 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 15s - loss: 1.0686 - acc: 0.7376 - val_loss: 7.1724e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 15s - loss: 0.9705 - acc: 0.7722 - val_loss: 2.5758e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 15s - loss: 0.8717 - acc: 0.8091 - val_loss: 4.5232e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 15s - loss: 0.7748 - acc: 0.8443 - val_loss: 4.2465e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 15s - loss: 0.6806 - acc: 0.8773 - val_loss: 2.0584e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 15s - loss: 0.5907 - acc: 0.9085 - val_loss: 3.4827e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 15s - loss: 0.5082 - acc: 0.9342 - val_loss: 8.1423e-05 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 15s - loss: 0.4319 - acc: 0.9573 - val_loss: 1.2148e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 15s - loss: 0.3648 - acc: 0.9732 - val_loss: 1.6703e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 15s - loss: 0.3067 - acc: 0.9849 - val_loss: 3.2664e-05 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 15s - loss: 0.2563 - acc: 0.9926 - val_loss: 6.9680e-05 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 16s - loss: 0.2155 - acc: 0.9970 - val_loss: 7.1945e-05 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 15s - loss: 0.1813 - acc: 0.9988 - val_loss: 2.4319e-05 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 15s - loss: 0.1544 - acc: 0.9996 - val_loss: 2.8015e-05 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 15s - loss: 0.1323 - acc: 0.9998 - val_loss: 1.6928e-05 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 16s - loss: 0.1147 - acc: 0.9999 - val_loss: 2.2292e-05 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 16s - loss: 0.1003 - acc: 0.9999 - val_loss: 1.0967e-05 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 16s - loss: 0.0888 - acc: 1.0000 - val_loss: 8.2255e-06 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 16s - loss: 0.0791 - acc: 1.0000 - val_loss: 1.4186e-05 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 16s - loss: 0.0711 - acc: 1.0000 - val_loss: 7.5698e-06 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 16s - loss: 0.0644 - acc: 1.0000 - val_loss: 6.0201e-06 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 17s - loss: 0.0586 - acc: 1.0000 - val_loss: 7.3314e-06 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      " - 16s - loss: 0.0536 - acc: 1.0000 - val_loss: 7.3910e-06 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 16s - loss: 0.0494 - acc: 1.0000 - val_loss: 6.5565e-06 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 16s - loss: 0.0457 - acc: 1.0000 - val_loss: 5.1260e-06 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 15s - loss: 0.0424 - acc: 1.0000 - val_loss: 4.5300e-06 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 15s - loss: 0.0396 - acc: 1.0000 - val_loss: 4.0531e-06 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 16s - loss: 0.0370 - acc: 1.0000 - val_loss: 2.8610e-06 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 14s - loss: 0.0347 - acc: 1.0000 - val_loss: 2.6822e-06 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 15s - loss: 0.0327 - acc: 1.0000 - val_loss: 2.8610e-06 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 15s - loss: 0.0309 - acc: 1.0000 - val_loss: 3.0994e-06 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 13s - loss: 0.0292 - acc: 1.0000 - val_loss: 2.0266e-06 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 13s - loss: 0.0277 - acc: 1.0000 - val_loss: 2.4438e-06 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 13s - loss: 0.0263 - acc: 1.0000 - val_loss: 2.0266e-06 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 12s - loss: 0.0250 - acc: 1.0000 - val_loss: 1.6689e-06 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 12s - loss: 0.0239 - acc: 1.0000 - val_loss: 1.7881e-06 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 12s - loss: 0.0228 - acc: 1.0000 - val_loss: 2.1458e-06 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 12s - loss: 0.0218 - acc: 1.0000 - val_loss: 1.5497e-06 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 11s - loss: 0.0209 - acc: 1.0000 - val_loss: 1.7881e-06 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 12s - loss: 0.0201 - acc: 1.0000 - val_loss: 1.6689e-06 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 12s - loss: 0.0193 - acc: 1.0000 - val_loss: 1.1921e-06 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 12s - loss: 0.0185 - acc: 1.0000 - val_loss: 1.4305e-06 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 12s - loss: 0.0178 - acc: 1.0000 - val_loss: 1.3113e-06 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 13s - loss: 0.0172 - acc: 1.0000 - val_loss: 1.1325e-06 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 13s - loss: 0.0166 - acc: 1.0000 - val_loss: 1.1921e-06 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 12s - loss: 0.0160 - acc: 1.0000 - val_loss: 8.9407e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 12s - loss: 0.0155 - acc: 1.0000 - val_loss: 8.9407e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 12s - loss: 0.0150 - acc: 1.0000 - val_loss: 1.0729e-06 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 12s - loss: 0.0145 - acc: 1.0000 - val_loss: 8.9407e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 11s - loss: 0.0141 - acc: 1.0000 - val_loss: 8.9407e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 11s - loss: 0.0137 - acc: 1.0000 - val_loss: 8.3447e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 11s - loss: 0.0133 - acc: 1.0000 - val_loss: 7.7486e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 11s - loss: 0.0129 - acc: 1.0000 - val_loss: 7.1526e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 12s - loss: 0.0125 - acc: 1.0000 - val_loss: 7.1526e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 11s - loss: 0.0122 - acc: 1.0000 - val_loss: 8.3447e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 11s - loss: 0.0119 - acc: 1.0000 - val_loss: 7.1526e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 11s - loss: 0.0115 - acc: 1.0000 - val_loss: 7.1526e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 11s - loss: 0.0112 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 11s - loss: 0.0110 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 12s - loss: 0.0107 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 11s - loss: 0.0104 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 11s - loss: 0.0102 - acc: 1.0000 - val_loss: 5.3644e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMzyHBTMzCzPQcHMzPL+D+r4jSukAPcoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12fdeb320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = [[4,4],[16,16],[64,64],[256,256],[1024, 1024]]\n",
    "noise_levels = [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "#noise_levels = [0.0, 0.2]\n",
    "\n",
    "\n",
    "for n_level in noise_levels:\n",
    "    x_data = Add_noise(n_level, X_train)\n",
    "    val_acc = []\n",
    "    for layer in layers:\n",
    "        model = build_network(params['activation'], layer, params['input_dim'], params['output_dim'])\n",
    "        r = model.fit(x=x_data, y=Y_train, \n",
    "                      verbose = 2, \n",
    "                      batch_size = params['batch_size'],\n",
    "                      epochs     = params['num_epochs'],\n",
    "                      validation_data=(X_test[:1], Y_test[:1]),\n",
    "                      shuffle=True)\n",
    "        \n",
    "        acc.append(r.history['acc'][-1])   \n",
    "    plt.plot(acc, label = 'noise_level '+ str(n_level))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('hidden units')\n",
    "plt.ylabel('training accuracy')\n",
    "plt.xticks(np.arange(len(layers)), ['4','16','64','256','1024'])\n",
    "plt.savefig('effect_of_noise.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time of Convergence with hidden size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.8516 - acc: 0.7914 - val_loss: 0.0303 - val_acc: 1.0000\n",
      "1\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.3924 - acc: 0.8923 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "2\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.3288 - acc: 0.9070 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "3\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.2950 - acc: 0.9170 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "4\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.2712 - acc: 0.9238 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "5\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.2523 - acc: 0.9289 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "6\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.2364 - acc: 0.9330 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "7\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.2225 - acc: 0.9377 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "8\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.2102 - acc: 0.9408 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "9\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1994 - acc: 0.9441 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "10\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1896 - acc: 0.9467 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "11\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1804 - acc: 0.9490 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "12\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.1721 - acc: 0.9515 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "13\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1645 - acc: 0.9546 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "14\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1572 - acc: 0.9557 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "15\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.1508 - acc: 0.9580 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "16\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1446 - acc: 0.9596 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "17\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1388 - acc: 0.9614 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "18\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.1334 - acc: 0.9630 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "19\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.1283 - acc: 0.9643 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "20\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.1236 - acc: 0.9660 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "21\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1194 - acc: 0.9669 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "22\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1150 - acc: 0.9682 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "23\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.1112 - acc: 0.9692 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "24\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1074 - acc: 0.9700 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "25\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1039 - acc: 0.9709 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "26\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.1004 - acc: 0.9723 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "27\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0973 - acc: 0.9731 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "28\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0942 - acc: 0.9738 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "29\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0914 - acc: 0.9744 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "30\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0887 - acc: 0.9755 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "31\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0860 - acc: 0.9760 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "32\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0836 - acc: 0.9773 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "33\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0813 - acc: 0.9775 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "34\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0788 - acc: 0.9784 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "35\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0766 - acc: 0.9790 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "36\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0747 - acc: 0.9792 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "37\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0726 - acc: 0.9799 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "38\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0707 - acc: 0.9804 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "39\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0688 - acc: 0.9812 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "40\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0670 - acc: 0.9816 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "41\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0652 - acc: 0.9822 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "42\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0637 - acc: 0.9825 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "43\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0621 - acc: 0.9833 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "44\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0604 - acc: 0.9837 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "45\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0590 - acc: 0.9837 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "46\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0576 - acc: 0.9848 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "47\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0562 - acc: 0.9849 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "48\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0547 - acc: 0.9855 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "49\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0534 - acc: 0.9860 - val_loss: 7.8280e-04 - val_acc: 1.0000\n",
      "50\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0524 - acc: 0.9862 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "51\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0510 - acc: 0.9866 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "52\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0499 - acc: 0.9870 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "53\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0486 - acc: 0.9875 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "54\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0476 - acc: 0.9877 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "55\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0464 - acc: 0.9880 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "56\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0454 - acc: 0.9883 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "57\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0444 - acc: 0.9888 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "58\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0434 - acc: 0.9891 - val_loss: 9.7961e-04 - val_acc: 1.0000\n",
      "59\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0423 - acc: 0.9893 - val_loss: 8.3094e-04 - val_acc: 1.0000\n",
      "60\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0414 - acc: 0.9895 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "61\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0405 - acc: 0.9898 - val_loss: 7.1855e-04 - val_acc: 1.0000\n",
      "62\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0397 - acc: 0.9900 - val_loss: 7.4062e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.7469 - acc: 0.8290 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "1\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.3612 - acc: 0.9018 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "2\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.3063 - acc: 0.9139 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "3\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.2758 - acc: 0.9225 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "4\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.2535 - acc: 0.9283 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "5\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 14s - loss: 0.2353 - acc: 0.9338 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "6\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 14s - loss: 0.2196 - acc: 0.9382 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "7\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 15s - loss: 0.2057 - acc: 0.9425 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "8\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 15s - loss: 0.1934 - acc: 0.9459 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "9\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 14s - loss: 0.1821 - acc: 0.9496 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "10\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1717 - acc: 0.9523 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "11\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1623 - acc: 0.9548 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "12\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1538 - acc: 0.9571 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "13\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1459 - acc: 0.9594 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "14\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1389 - acc: 0.9618 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "15\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1323 - acc: 0.9631 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "16\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1262 - acc: 0.9653 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "17\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1206 - acc: 0.9667 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "18\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1153 - acc: 0.9683 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "19\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1106 - acc: 0.9697 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "20\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1059 - acc: 0.9712 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "21\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.1018 - acc: 0.9718 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "22\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0978 - acc: 0.9732 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "23\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0942 - acc: 0.9743 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "24\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0905 - acc: 0.9754 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "25\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0873 - acc: 0.9760 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "26\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0841 - acc: 0.9775 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "27\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 14s - loss: 0.0810 - acc: 0.9783 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "28\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0784 - acc: 0.9789 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "29\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0754 - acc: 0.9801 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "30\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0731 - acc: 0.9806 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "31\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0707 - acc: 0.9814 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "32\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0683 - acc: 0.9819 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "33\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0662 - acc: 0.9826 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "34\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0641 - acc: 0.9832 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "35\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0620 - acc: 0.9840 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "36\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0602 - acc: 0.9841 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "37\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0583 - acc: 0.9849 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "38\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0566 - acc: 0.9855 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "39\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0549 - acc: 0.9861 - val_loss: 9.1094e-04 - val_acc: 1.0000\n",
      "40\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0531 - acc: 0.9870 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "41\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0517 - acc: 0.9870 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "42\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0501 - acc: 0.9878 - val_loss: 9.7579e-04 - val_acc: 1.0000\n",
      "43\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0487 - acc: 0.9882 - val_loss: 8.5164e-04 - val_acc: 1.0000\n",
      "44\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "45\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0460 - acc: 0.9888 - val_loss: 6.3809e-04 - val_acc: 1.0000\n",
      "46\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0447 - acc: 0.9891 - val_loss: 7.4492e-04 - val_acc: 1.0000\n",
      "47\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0434 - acc: 0.9896 - val_loss: 8.8606e-04 - val_acc: 1.0000\n",
      "48\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0422 - acc: 0.9898 - val_loss: 6.8963e-04 - val_acc: 1.0000\n",
      "49\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.0409 - acc: 0.9902 - val_loss: 9.6027e-04 - val_acc: 1.0000\n",
      "50\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 160s - loss: 0.6933 - acc: 0.8473 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "1\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 174s - loss: 0.3467 - acc: 0.9063 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "2\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 162s - loss: 0.2943 - acc: 0.9187 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "3\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 159s - loss: 0.2643 - acc: 0.9266 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "4\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 165s - loss: 0.2420 - acc: 0.9331 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "5\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 163s - loss: 0.2238 - acc: 0.9380 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "6\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 173s - loss: 0.2081 - acc: 0.9428 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "7\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 173s - loss: 0.1942 - acc: 0.9465 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "8\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 161s - loss: 0.1817 - acc: 0.9504 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "9\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 158s - loss: 0.1710 - acc: 0.9529 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "10\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 181s - loss: 0.1607 - acc: 0.9555 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "11\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 162s - loss: 0.1518 - acc: 0.9582 - val_loss: 0.0053 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 166s - loss: 0.1433 - acc: 0.9606 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "13\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 179s - loss: 0.1360 - acc: 0.9626 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "14\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 164s - loss: 0.1289 - acc: 0.9649 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "15\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 157s - loss: 0.1225 - acc: 0.9673 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "16\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 157s - loss: 0.1166 - acc: 0.9689 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "17\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 156s - loss: 0.1111 - acc: 0.9701 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "18\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 156s - loss: 0.1062 - acc: 0.9713 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "19\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 156s - loss: 0.1014 - acc: 0.9729 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "20\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 154s - loss: 0.0969 - acc: 0.9744 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "21\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 154s - loss: 0.0931 - acc: 0.9748 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "22\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 154s - loss: 0.0892 - acc: 0.9759 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "23\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 156s - loss: 0.0855 - acc: 0.9772 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "24\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 156s - loss: 0.0823 - acc: 0.9780 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "25\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 160s - loss: 0.0791 - acc: 0.9791 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "26\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 158s - loss: 0.0761 - acc: 0.9802 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "27\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 168s - loss: 0.0732 - acc: 0.9809 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "28\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 168s - loss: 0.0705 - acc: 0.9813 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "29\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n",
      " - 174s - loss: 0.0679 - acc: 0.9823 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "30\n",
      "Train on 60000 samples, validate on 1 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c5ccc991052e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#                      callbacks = callbacks_list,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                       shuffle=True)\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m#print(r.history['acc'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers = [[256,256],[1024, 1024], [4096, 4096]]\n",
    "noise_levels = [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "#noise_levels = [0.8]\n",
    "Overall_time = []\n",
    "for n_level in noise_levels:\n",
    "    x_data = Add_noise(n_level, X_train)\n",
    "    time_conv = []\n",
    "    for layer in layers:\n",
    "        model = build_network(params['activation'], layer , params['input_dim'], params['output_dim'])\n",
    "        start = time.time()\n",
    "#        earlystop = EarlyStopping(monitor='acc', min_delta=0.001, patience=5, \n",
    "#                          verbose=1, mode='auto')\n",
    "#        callbacks_list = [earlystop]\n",
    "        acc = [0]\n",
    "        iteration = 0\n",
    "        print(\"n_level: \", n_level, \", num_neurons: \", layer)\n",
    "        while acc[0] < 0.99:\n",
    "            r = model.fit(x=x_data, y=Y_train, \n",
    "                      verbose = 2, \n",
    "                      batch_size = params['batch_size'],\n",
    "                      epochs     = 1,\n",
    "                      validation_data=(X_test[:1], Y_test[:1]),\n",
    "#                      callbacks = callbacks_list,\n",
    "                      shuffle=True)\n",
    "            #print(r.history['acc'])\n",
    "            acc = r.history['acc']\n",
    "            iteration += 1\n",
    "            print(iteration)\n",
    "        end = time.time()\n",
    "        time_conv.append(end - start)\n",
    "    Overall_time.append(time_conv)\n",
    "    time_conv = [z/float(max(time_conv)) for z in time_conv]\n",
    "    plt.plot(time_conv,  label = 'noise_level '+ str(n_level))\n",
    "    \n",
    "plt.xlabel('Hidden Units')\n",
    "plt.ylabel('Time to convergence')\n",
    "plt.xticks(np.arange(3), ['256','1024','4096'])\n",
    "plt.legend()\n",
    "np.save('Overall_time.npy', Overall_time)\n",
    "plt.savefig('time_to_conv.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    plt.plot(Overall_time[i], label = 'noise_level '+str(noise_levels[i]))\n",
    "plt.xlabel('Hidden Units')\n",
    "plt.ylabel('Time to convergence')\n",
    "plt.xticks(np.arange(3), ['256','1024','4096'])\n",
    "plt.legend()\n",
    "np.save('Overall_time.npy', Overall_time)\n",
    "plt.savefig('time_to_conv.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time of Convergence with dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 2.3482 - acc: 0.0700 - val_loss: 5.9529 - val_acc: 0.1034\n",
      "Epoch 2/100\n",
      " - 0s - loss: 4.0452 - acc: 0.1600 - val_loss: 3.4348 - val_acc: 0.4379\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.4446 - acc: 0.5700 - val_loss: 2.5062 - val_acc: 0.5582\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.8579 - acc: 0.7300 - val_loss: 2.0308 - val_acc: 0.5868\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.3507 - acc: 0.7900 - val_loss: 1.7404 - val_acc: 0.5756\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.9666 - acc: 0.7900 - val_loss: 1.3394 - val_acc: 0.6076\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4918 - acc: 0.8500 - val_loss: 1.0149 - val_acc: 0.6972\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1786 - acc: 0.9900 - val_loss: 0.9266 - val_acc: 0.7176\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0849 - acc: 1.0000 - val_loss: 1.0361 - val_acc: 0.6715\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0847 - acc: 0.9800 - val_loss: 1.1987 - val_acc: 0.6406\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0984 - acc: 0.9800 - val_loss: 1.2480 - val_acc: 0.6362\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0670 - acc: 0.9900 - val_loss: 1.1816 - val_acc: 0.6571\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0298 - acc: 1.0000 - val_loss: 1.0825 - val_acc: 0.6873\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0120 - acc: 1.0000 - val_loss: 1.0014 - val_acc: 0.7177\n",
      "Epoch 00014: early stopping\n",
      "Train on 781 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.7821 - acc: 0.4392 - val_loss: 1.0134 - val_acc: 0.7411\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.7307 - acc: 0.8348 - val_loss: 0.4881 - val_acc: 0.8480\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2567 - acc: 0.9373 - val_loss: 0.4521 - val_acc: 0.8701\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1032 - acc: 0.9667 - val_loss: 0.3975 - val_acc: 0.8883\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0390 - acc: 0.9962 - val_loss: 0.4474 - val_acc: 0.8798\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0190 - acc: 0.9962 - val_loss: 0.4119 - val_acc: 0.8853\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0120 - acc: 0.9974 - val_loss: 0.4202 - val_acc: 0.8925\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4099 - val_acc: 0.8977\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4346 - val_acc: 0.8936\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4232 - val_acc: 0.8958\n",
      "Epoch 11/100\n",
      " - 0s - loss: 9.8765e-04 - acc: 1.0000 - val_loss: 0.4117 - val_acc: 0.8988\n",
      "Epoch 12/100\n",
      " - 0s - loss: 8.1761e-04 - acc: 1.0000 - val_loss: 0.4102 - val_acc: 0.8997\n",
      "Epoch 13/100\n",
      " - 0s - loss: 6.6516e-04 - acc: 1.0000 - val_loss: 0.4118 - val_acc: 0.9005\n",
      "Epoch 00013: early stopping\n",
      "Train on 3125 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.1252 - acc: 0.7315 - val_loss: 0.3175 - val_acc: 0.9017\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2151 - acc: 0.9318 - val_loss: 0.2469 - val_acc: 0.9236\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0912 - acc: 0.9718 - val_loss: 0.2233 - val_acc: 0.9340\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0351 - acc: 0.9901 - val_loss: 0.2274 - val_acc: 0.9355\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0144 - acc: 0.9968 - val_loss: 0.2273 - val_acc: 0.9398\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0105 - acc: 0.9974 - val_loss: 0.2418 - val_acc: 0.9392\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0151 - acc: 0.9942 - val_loss: 0.2715 - val_acc: 0.9362\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0438 - acc: 0.9875 - val_loss: 0.2548 - val_acc: 0.9364\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0278 - acc: 0.9907 - val_loss: 0.2665 - val_acc: 0.9362\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0125 - acc: 0.9962 - val_loss: 0.2698 - val_acc: 0.9361\n",
      "Epoch 00010: early stopping\n",
      "Train on 12500 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.3929 - acc: 0.8899 - val_loss: 0.1813 - val_acc: 0.9420\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.1327 - acc: 0.9595 - val_loss: 0.1604 - val_acc: 0.9505\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.0824 - acc: 0.9734 - val_loss: 0.1555 - val_acc: 0.9564\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.0602 - acc: 0.9807 - val_loss: 0.1275 - val_acc: 0.9662\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.0494 - acc: 0.9851 - val_loss: 0.1873 - val_acc: 0.9551\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.0452 - acc: 0.9865 - val_loss: 0.2073 - val_acc: 0.9538\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0483 - acc: 0.9856 - val_loss: 0.1940 - val_acc: 0.9592\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0431 - acc: 0.9875 - val_loss: 0.1665 - val_acc: 0.9646\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0416 - acc: 0.9874 - val_loss: 0.1861 - val_acc: 0.9625\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0407 - acc: 0.9883 - val_loss: 0.1925 - val_acc: 0.9613\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0331 - acc: 0.9909 - val_loss: 0.1684 - val_acc: 0.9672\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0141 - acc: 0.9964 - val_loss: 0.1817 - val_acc: 0.9658\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.0257 - acc: 0.9928 - val_loss: 0.2193 - val_acc: 0.9611\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.0304 - acc: 0.9924 - val_loss: 0.1994 - val_acc: 0.9625\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.0520 - acc: 0.9890 - val_loss: 0.2449 - val_acc: 0.9563\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.0398 - acc: 0.9889 - val_loss: 0.3044 - val_acc: 0.9544\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.0881 - acc: 0.9832 - val_loss: 0.3775 - val_acc: 0.9495\n",
      "Epoch 00017: early stopping\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.2314 - acc: 0.9346 - val_loss: 0.1106 - val_acc: 0.9632\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0949 - acc: 0.9713 - val_loss: 0.1147 - val_acc: 0.9691\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0696 - acc: 0.9791 - val_loss: 0.1039 - val_acc: 0.9707\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0614 - acc: 0.9816 - val_loss: 0.1084 - val_acc: 0.9738\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0520 - acc: 0.9840 - val_loss: 0.1206 - val_acc: 0.9710\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0478 - acc: 0.9869 - val_loss: 0.1072 - val_acc: 0.9747\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0499 - acc: 0.9864 - val_loss: 0.1482 - val_acc: 0.9684\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0438 - acc: 0.9878 - val_loss: 0.1168 - val_acc: 0.9751\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0270 - acc: 0.9918 - val_loss: 0.1230 - val_acc: 0.9772\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0435 - acc: 0.9888 - val_loss: 0.1761 - val_acc: 0.9713\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0366 - acc: 0.9909 - val_loss: 0.1219 - val_acc: 0.9787\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.0357 - acc: 0.9909 - val_loss: 0.2015 - val_acc: 0.9645\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0315 - acc: 0.9919 - val_loss: 0.1444 - val_acc: 0.9756\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.0318 - acc: 0.9928 - val_loss: 0.1581 - val_acc: 0.9743\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.0301 - acc: 0.9930 - val_loss: 0.1402 - val_acc: 0.9779\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0519 - acc: 0.9899 - val_loss: 0.2365 - val_acc: 0.9703\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.0453 - acc: 0.9913 - val_loss: 0.1951 - val_acc: 0.9746\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.0281 - acc: 0.9947 - val_loss: 0.1848 - val_acc: 0.9769\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.0285 - acc: 0.9945 - val_loss: 0.1728 - val_acc: 0.9760\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.0243 - acc: 0.9948 - val_loss: 0.1845 - val_acc: 0.9777\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.0438 - acc: 0.9923 - val_loss: 0.2117 - val_acc: 0.9750\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.0438 - acc: 0.9930 - val_loss: 0.2135 - val_acc: 0.9768\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.0377 - acc: 0.9939 - val_loss: 0.2392 - val_acc: 0.9753\n",
      "Epoch 00023: early stopping\n",
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.3120 - acc: 0.0900 - val_loss: 3.3950 - val_acc: 0.3299\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.6666 - acc: 0.5900 - val_loss: 2.9684 - val_acc: 0.5302\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.4498 - acc: 0.7800 - val_loss: 2.4144 - val_acc: 0.5411\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.8933 - acc: 0.8200 - val_loss: 1.5312 - val_acc: 0.5958\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.3420 - acc: 0.9000 - val_loss: 1.1471 - val_acc: 0.6656\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1321 - acc: 0.9400 - val_loss: 1.0197 - val_acc: 0.6824\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0366 - acc: 1.0000 - val_loss: 1.0585 - val_acc: 0.6676\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 1.3224 - val_acc: 0.6175\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0173 - acc: 1.0000 - val_loss: 1.6345 - val_acc: 0.5894\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0185 - acc: 1.0000 - val_loss: 1.8451 - val_acc: 0.5863\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0148 - acc: 1.0000 - val_loss: 1.9650 - val_acc: 0.5911\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0125 - acc: 1.0000 - val_loss: 2.0182 - val_acc: 0.6005\n",
      "Epoch 00012: early stopping\n",
      "Train on 781 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.8069 - acc: 0.3585 - val_loss: 0.9677 - val_acc: 0.7505\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.8181 - acc: 0.8207 - val_loss: 0.4755 - val_acc: 0.8434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      " - 0s - loss: 0.2626 - acc: 0.9334 - val_loss: 0.4362 - val_acc: 0.8714\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1097 - acc: 0.9693 - val_loss: 0.5100 - val_acc: 0.8555\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0578 - acc: 0.9846 - val_loss: 0.4578 - val_acc: 0.8743\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0273 - acc: 0.9923 - val_loss: 0.4597 - val_acc: 0.8763\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5137 - val_acc: 0.8676\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0118 - acc: 0.9974 - val_loss: 0.4344 - val_acc: 0.8915\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4463 - val_acc: 0.8907\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.4224 - val_acc: 0.8912\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4513 - val_acc: 0.8869\n",
      "Epoch 12/100\n",
      " - 0s - loss: 8.7355e-04 - acc: 1.0000 - val_loss: 0.4291 - val_acc: 0.8955\n",
      "Epoch 00012: early stopping\n",
      "Train on 3125 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.2872 - acc: 0.6234 - val_loss: 0.3670 - val_acc: 0.8886\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2561 - acc: 0.9424 - val_loss: 0.3703 - val_acc: 0.8934\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.1178 - acc: 0.9674 - val_loss: 0.2710 - val_acc: 0.9264\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0443 - acc: 0.9875 - val_loss: 0.2588 - val_acc: 0.9326\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0233 - acc: 0.9926 - val_loss: 0.2655 - val_acc: 0.9320\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0103 - acc: 0.9971 - val_loss: 0.2775 - val_acc: 0.9366\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0060 - acc: 0.9990 - val_loss: 0.3043 - val_acc: 0.9304\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0155 - acc: 0.9984 - val_loss: 0.2783 - val_acc: 0.9376\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0095 - acc: 0.9974 - val_loss: 0.3549 - val_acc: 0.9243\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0375 - acc: 0.9888 - val_loss: 0.5775 - val_acc: 0.8853\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0481 - acc: 0.9853 - val_loss: 0.6513 - val_acc: 0.8782\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0412 - acc: 0.9850 - val_loss: 0.4492 - val_acc: 0.9109\n",
      "Epoch 00012: early stopping\n",
      "Train on 12500 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.9241 - acc: 0.7139 - val_loss: 0.2220 - val_acc: 0.9275\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3972 - acc: 0.8813 - val_loss: 0.2090 - val_acc: 0.9397\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.1191 - acc: 0.9664 - val_loss: 0.2552 - val_acc: 0.9293\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.0806 - acc: 0.9766 - val_loss: 0.2144 - val_acc: 0.9436\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.0432 - acc: 0.9870 - val_loss: 0.1472 - val_acc: 0.9616\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.0365 - acc: 0.9894 - val_loss: 0.2157 - val_acc: 0.9487\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0380 - acc: 0.9891 - val_loss: 0.2022 - val_acc: 0.9539\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0528 - acc: 0.9856 - val_loss: 0.2561 - val_acc: 0.9460\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0311 - acc: 0.9904 - val_loss: 0.2339 - val_acc: 0.9557\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0252 - acc: 0.9931 - val_loss: 0.2700 - val_acc: 0.9517\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0186 - acc: 0.9953 - val_loss: 0.2185 - val_acc: 0.9583\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0369 - acc: 0.9906 - val_loss: 0.3011 - val_acc: 0.9475\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.0374 - acc: 0.9902 - val_loss: 0.2665 - val_acc: 0.9547\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.0362 - acc: 0.9903 - val_loss: 0.3069 - val_acc: 0.9496\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.0361 - acc: 0.9912 - val_loss: 0.3420 - val_acc: 0.9498\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1370 - acc: 0.9613 - val_loss: 0.2358 - val_acc: 0.9551\n",
      "Epoch 00016: early stopping\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.6634 - acc: 0.7643 - val_loss: 0.1174 - val_acc: 0.9642\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.4969 - acc: 0.8289 - val_loss: 0.1092 - val_acc: 0.9660\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.2587 - acc: 0.9218 - val_loss: 0.1577 - val_acc: 0.9599\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0972 - acc: 0.9745 - val_loss: 0.1573 - val_acc: 0.9642\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0568 - acc: 0.9851 - val_loss: 0.1768 - val_acc: 0.9623\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0544 - acc: 0.9865 - val_loss: 0.1715 - val_acc: 0.9712\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0527 - acc: 0.9869 - val_loss: 0.1557 - val_acc: 0.9690\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0883 - acc: 0.9751 - val_loss: 0.1664 - val_acc: 0.9674\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0720 - acc: 0.9782 - val_loss: 0.1638 - val_acc: 0.9710\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0501 - acc: 0.9861 - val_loss: 0.1884 - val_acc: 0.9680\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0526 - acc: 0.9862 - val_loss: 0.1866 - val_acc: 0.9667\n",
      "Epoch 00011: early stopping\n",
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.2633 - acc: 0.2200 - val_loss: 4.4810 - val_acc: 0.2682\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.1400 - acc: 0.4400 - val_loss: 4.6974 - val_acc: 0.3920\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.9696 - acc: 0.5800 - val_loss: 2.7325 - val_acc: 0.4607\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6879 - acc: 0.7900 - val_loss: 1.7809 - val_acc: 0.4595\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2072 - acc: 0.9400 - val_loss: 1.4638 - val_acc: 0.5333\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1536 - acc: 0.9600 - val_loss: 1.2349 - val_acc: 0.6300\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0619 - acc: 1.0000 - val_loss: 1.3277 - val_acc: 0.6379\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0330 - acc: 1.0000 - val_loss: 1.5071 - val_acc: 0.6081\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0181 - acc: 1.0000 - val_loss: 1.6900 - val_acc: 0.5705\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0158 - acc: 1.0000 - val_loss: 1.8338 - val_acc: 0.5551\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0149 - acc: 1.0000 - val_loss: 1.9326 - val_acc: 0.5567\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0107 - acc: 1.0000 - val_loss: 2.0123 - val_acc: 0.5601\n",
      "Epoch 00012: early stopping\n",
      "Train on 781 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 3.0073 - acc: 0.2830 - val_loss: 1.2119 - val_acc: 0.6877\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.0636 - acc: 0.7875 - val_loss: 0.5802 - val_acc: 0.8107\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2988 - acc: 0.9539 - val_loss: 0.6610 - val_acc: 0.8116\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0952 - acc: 0.9744 - val_loss: 0.5543 - val_acc: 0.8612\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0331 - acc: 0.9936 - val_loss: 0.6860 - val_acc: 0.8417\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0130 - acc: 0.9974 - val_loss: 0.6087 - val_acc: 0.8613\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0115 - acc: 0.9949 - val_loss: 0.6540 - val_acc: 0.8565\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0057 - acc: 0.9987 - val_loss: 0.6326 - val_acc: 0.8644\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0036 - acc: 0.9987 - val_loss: 0.5673 - val_acc: 0.8759\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5557 - val_acc: 0.8814\n",
      "Epoch 11/100\n",
      " - 0s - loss: 5.9717e-04 - acc: 1.0000 - val_loss: 0.5793 - val_acc: 0.8768\n",
      "Epoch 12/100\n",
      " - 0s - loss: 5.6981e-04 - acc: 1.0000 - val_loss: 0.5891 - val_acc: 0.8744\n",
      "Epoch 13/100\n",
      " - 0s - loss: 4.0520e-04 - acc: 1.0000 - val_loss: 0.5877 - val_acc: 0.8760\n",
      "Epoch 14/100\n",
      " - 0s - loss: 3.2946e-04 - acc: 1.0000 - val_loss: 0.5865 - val_acc: 0.8758\n",
      "Epoch 15/100\n",
      " - 0s - loss: 2.9522e-04 - acc: 1.0000 - val_loss: 0.5854 - val_acc: 0.8767\n",
      "Epoch 00015: early stopping\n",
      "Train on 3125 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.8987 - acc: 0.4470 - val_loss: 0.4026 - val_acc: 0.8796\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.7976 - acc: 0.7987 - val_loss: 0.3414 - val_acc: 0.9024\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2455 - acc: 0.9488 - val_loss: 0.3113 - val_acc: 0.9145\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0643 - acc: 0.9830 - val_loss: 0.3440 - val_acc: 0.9109\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0456 - acc: 0.9869 - val_loss: 0.4224 - val_acc: 0.8954\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0227 - acc: 0.9946 - val_loss: 0.3962 - val_acc: 0.9079\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0171 - acc: 0.9949 - val_loss: 0.4243 - val_acc: 0.9130\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0182 - acc: 0.9952 - val_loss: 0.3575 - val_acc: 0.9188\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0072 - acc: 0.9990 - val_loss: 0.4242 - val_acc: 0.9116\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0100 - acc: 0.9978 - val_loss: 0.3871 - val_acc: 0.9205\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0124 - acc: 0.9974 - val_loss: 0.4082 - val_acc: 0.9203\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0737 - acc: 0.9789 - val_loss: 0.5373 - val_acc: 0.8974\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0565 - acc: 0.9875 - val_loss: 0.6282 - val_acc: 0.8892\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0438 - acc: 0.9904 - val_loss: 0.5959 - val_acc: 0.8859\n",
      "Epoch 00014: early stopping\n",
      "Train on 12500 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.2680 - acc: 0.5567 - val_loss: 0.2161 - val_acc: 0.9296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      " - 2s - loss: 0.7406 - acc: 0.7657 - val_loss: 0.2372 - val_acc: 0.9307\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.1958 - acc: 0.9502 - val_loss: 0.2825 - val_acc: 0.9374\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.0901 - acc: 0.9779 - val_loss: 0.3082 - val_acc: 0.9415\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.0688 - acc: 0.9831 - val_loss: 0.2657 - val_acc: 0.9466\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.0449 - acc: 0.9881 - val_loss: 0.3067 - val_acc: 0.9399\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0372 - acc: 0.9894 - val_loss: 0.2675 - val_acc: 0.9486\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0307 - acc: 0.9922 - val_loss: 0.2658 - val_acc: 0.9495\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0263 - acc: 0.9930 - val_loss: 0.3003 - val_acc: 0.9496\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0262 - acc: 0.9930 - val_loss: 0.3474 - val_acc: 0.9488\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0332 - acc: 0.9922 - val_loss: 0.3454 - val_acc: 0.9500\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0640 - acc: 0.9856 - val_loss: 0.4011 - val_acc: 0.9435\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1569 - acc: 0.9526 - val_loss: 0.3839 - val_acc: 0.9478\n",
      "Epoch 00013: early stopping\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.1212 - acc: 0.5893 - val_loss: 0.1361 - val_acc: 0.9572\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.9611 - acc: 0.6515 - val_loss: 0.0938 - val_acc: 0.9722\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.7313 - acc: 0.7528 - val_loss: 0.1715 - val_acc: 0.9536\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.3421 - acc: 0.8915 - val_loss: 0.1994 - val_acc: 0.9622\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.1636 - acc: 0.9546 - val_loss: 0.1840 - val_acc: 0.9668\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0965 - acc: 0.9748 - val_loss: 0.2248 - val_acc: 0.9606\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0856 - acc: 0.9779 - val_loss: 0.1941 - val_acc: 0.9683\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0851 - acc: 0.9789 - val_loss: 0.1670 - val_acc: 0.9725\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0894 - acc: 0.9753 - val_loss: 0.2113 - val_acc: 0.9682\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0835 - acc: 0.9765 - val_loss: 0.2746 - val_acc: 0.9624\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0719 - acc: 0.9805 - val_loss: 0.1855 - val_acc: 0.9716\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.0552 - acc: 0.9852 - val_loss: 0.1875 - val_acc: 0.9722\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0615 - acc: 0.9829 - val_loss: 0.2027 - val_acc: 0.9715\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.0530 - acc: 0.9848 - val_loss: 0.2282 - val_acc: 0.9703\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.0705 - acc: 0.9813 - val_loss: 0.2204 - val_acc: 0.9681\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0509 - acc: 0.9871 - val_loss: 0.2243 - val_acc: 0.9681\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.0482 - acc: 0.9871 - val_loss: 0.2574 - val_acc: 0.9696\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.0659 - acc: 0.9837 - val_loss: 0.2219 - val_acc: 0.9723\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.0495 - acc: 0.9869 - val_loss: 0.2409 - val_acc: 0.9695\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.0565 - acc: 0.9855 - val_loss: 0.2242 - val_acc: 0.9727\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.0459 - acc: 0.9886 - val_loss: 0.2817 - val_acc: 0.9655\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.0577 - acc: 0.9857 - val_loss: 0.2382 - val_acc: 0.9717\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.0511 - acc: 0.9878 - val_loss: 0.3211 - val_acc: 0.9638\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.0526 - acc: 0.9879 - val_loss: 0.3144 - val_acc: 0.9652\n",
      "Epoch 25/100\n",
      " - 7s - loss: 0.0440 - acc: 0.9893 - val_loss: 0.2236 - val_acc: 0.9760\n",
      "Epoch 26/100\n",
      " - 7s - loss: 0.0528 - acc: 0.9883 - val_loss: 0.2549 - val_acc: 0.9722\n",
      "Epoch 00026: early stopping\n",
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.3126 - acc: 0.1300 - val_loss: 3.9215 - val_acc: 0.2543\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.2627 - acc: 0.4800 - val_loss: 3.6533 - val_acc: 0.2989\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.8187 - acc: 0.6200 - val_loss: 2.7649 - val_acc: 0.3528\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.1100 - acc: 0.7100 - val_loss: 2.1424 - val_acc: 0.4370\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2944 - acc: 0.9400 - val_loss: 2.0229 - val_acc: 0.4157\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1138 - acc: 0.9600 - val_loss: 1.6051 - val_acc: 0.5037\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0321 - acc: 1.0000 - val_loss: 1.4157 - val_acc: 0.5609\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0184 - acc: 1.0000 - val_loss: 1.5007 - val_acc: 0.5461\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0217 - acc: 1.0000 - val_loss: 1.6915 - val_acc: 0.5178\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0223 - acc: 1.0000 - val_loss: 1.8341 - val_acc: 0.5113\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0157 - acc: 1.0000 - val_loss: 1.9091 - val_acc: 0.5193\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0103 - acc: 1.0000 - val_loss: 1.9437 - val_acc: 0.5322\n",
      "Epoch 00012: early stopping\n",
      "Train on 781 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 3.5500 - acc: 0.2049 - val_loss: 1.6819 - val_acc: 0.4799\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.7856 - acc: 0.4994 - val_loss: 1.1322 - val_acc: 0.5911\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.0242 - acc: 0.8054 - val_loss: 0.6457 - val_acc: 0.8029\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3304 - acc: 0.9513 - val_loss: 0.5735 - val_acc: 0.8278\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0697 - acc: 0.9898 - val_loss: 0.6409 - val_acc: 0.8302\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0230 - acc: 0.9974 - val_loss: 0.5440 - val_acc: 0.8580\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.5910 - val_acc: 0.8456\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0056 - acc: 0.9987 - val_loss: 0.6396 - val_acc: 0.8458\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.7398 - val_acc: 0.8317\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6712 - val_acc: 0.8421\n",
      "Epoch 11/100\n",
      " - 0s - loss: 9.6267e-04 - acc: 1.0000 - val_loss: 0.6364 - val_acc: 0.8506\n",
      "Epoch 12/100\n",
      " - 0s - loss: 7.7020e-04 - acc: 1.0000 - val_loss: 0.6084 - val_acc: 0.8573\n",
      "Epoch 00012: early stopping\n",
      "Train on 3125 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.1561 - acc: 0.3306 - val_loss: 0.4377 - val_acc: 0.8625\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.1718 - acc: 0.6848 - val_loss: 0.5005 - val_acc: 0.8557\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4361 - acc: 0.9008 - val_loss: 0.4556 - val_acc: 0.8844\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0747 - acc: 0.9856 - val_loss: 0.4718 - val_acc: 0.8986\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0530 - acc: 0.9850 - val_loss: 0.5024 - val_acc: 0.8931\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0281 - acc: 0.9904 - val_loss: 0.4725 - val_acc: 0.9055\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0098 - acc: 0.9968 - val_loss: 0.4259 - val_acc: 0.9158\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0056 - acc: 0.9987 - val_loss: 0.4380 - val_acc: 0.9166\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0066 - acc: 0.9987 - val_loss: 0.4446 - val_acc: 0.9169\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0054 - acc: 0.9981 - val_loss: 0.4758 - val_acc: 0.9106\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0042 - acc: 0.9987 - val_loss: 0.4377 - val_acc: 0.9201\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0049 - acc: 0.9987 - val_loss: 0.4396 - val_acc: 0.9221\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0091 - acc: 0.9987 - val_loss: 0.4743 - val_acc: 0.9150\n",
      "Epoch 00013: early stopping\n",
      "Train on 12500 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.6850 - acc: 0.3911 - val_loss: 0.2836 - val_acc: 0.9095\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.2836 - acc: 0.5577 - val_loss: 0.2471 - val_acc: 0.9240\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.5229 - acc: 0.8495 - val_loss: 0.3485 - val_acc: 0.9267\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.1299 - acc: 0.9722 - val_loss: 0.4058 - val_acc: 0.9235\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.0554 - acc: 0.9875 - val_loss: 0.3668 - val_acc: 0.9384\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.0612 - acc: 0.9879 - val_loss: 0.5052 - val_acc: 0.9224\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0443 - acc: 0.9900 - val_loss: 0.3022 - val_acc: 0.9494\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0228 - acc: 0.9944 - val_loss: 0.4332 - val_acc: 0.9357\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0224 - acc: 0.9954 - val_loss: 0.3377 - val_acc: 0.9492\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0161 - acc: 0.9962 - val_loss: 0.4857 - val_acc: 0.9338\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0321 - acc: 0.9940 - val_loss: 0.6736 - val_acc: 0.9104\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0629 - acc: 0.9887 - val_loss: 0.5058 - val_acc: 0.9368\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.0604 - acc: 0.9876 - val_loss: 0.4225 - val_acc: 0.9448\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.2079 - acc: 0.9369 - val_loss: 0.4427 - val_acc: 0.9383\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.1972 - acc: 0.9375 - val_loss: 0.3689 - val_acc: 0.9457\n",
      "Epoch 00015: early stopping\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.5413 - acc: 0.4228 - val_loss: 0.1756 - val_acc: 0.9457\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.4161 - acc: 0.4736 - val_loss: 0.1728 - val_acc: 0.9480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      " - 7s - loss: 1.2158 - acc: 0.5733 - val_loss: 0.1295 - val_acc: 0.9647\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.7896 - acc: 0.7342 - val_loss: 0.1646 - val_acc: 0.9618\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.4366 - acc: 0.8584 - val_loss: 0.2233 - val_acc: 0.9595\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.2632 - acc: 0.9164 - val_loss: 0.2563 - val_acc: 0.9579\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.1987 - acc: 0.9401 - val_loss: 0.2750 - val_acc: 0.9591\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.1627 - acc: 0.9530 - val_loss: 0.2971 - val_acc: 0.9576\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.1377 - acc: 0.9597 - val_loss: 0.2620 - val_acc: 0.9651\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.1163 - acc: 0.9643 - val_loss: 0.2441 - val_acc: 0.9675\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.1110 - acc: 0.9666 - val_loss: 0.2989 - val_acc: 0.9650\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.1137 - acc: 0.9669 - val_loss: 0.2564 - val_acc: 0.9684\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0957 - acc: 0.9725 - val_loss: 0.2941 - val_acc: 0.9647\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.0944 - acc: 0.9751 - val_loss: 0.2951 - val_acc: 0.9644\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.0879 - acc: 0.9754 - val_loss: 0.3153 - val_acc: 0.9653\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0705 - acc: 0.9796 - val_loss: 0.3007 - val_acc: 0.9669\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.0981 - acc: 0.9751 - val_loss: 0.3239 - val_acc: 0.9652\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.0985 - acc: 0.9738 - val_loss: 0.2851 - val_acc: 0.9688\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.0597 - acc: 0.9834 - val_loss: 0.3243 - val_acc: 0.9634\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.0795 - acc: 0.9796 - val_loss: 0.3497 - val_acc: 0.9660\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.0782 - acc: 0.9805 - val_loss: 0.3108 - val_acc: 0.9651\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.0766 - acc: 0.9792 - val_loss: 0.3385 - val_acc: 0.9620\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.0576 - acc: 0.9849 - val_loss: 0.3176 - val_acc: 0.9659\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.0575 - acc: 0.9842 - val_loss: 0.3369 - val_acc: 0.9653\n",
      "Epoch 25/100\n",
      " - 7s - loss: 0.0609 - acc: 0.9845 - val_loss: 0.3272 - val_acc: 0.9678\n",
      "Epoch 26/100\n",
      " - 7s - loss: 0.0802 - acc: 0.9805 - val_loss: 0.3439 - val_acc: 0.9663\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.0687 - acc: 0.9830 - val_loss: 0.3166 - val_acc: 0.9682\n",
      "Epoch 28/100\n",
      " - 7s - loss: 0.0609 - acc: 0.9847 - val_loss: 0.3171 - val_acc: 0.9685\n",
      "Epoch 00028: early stopping\n",
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.3099 - acc: 0.1000 - val_loss: 5.8470 - val_acc: 0.1163\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.6734 - acc: 0.3300 - val_loss: 3.8921 - val_acc: 0.2894\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.9717 - acc: 0.7200 - val_loss: 3.9365 - val_acc: 0.2469\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.4892 - acc: 0.8200 - val_loss: 2.9938 - val_acc: 0.3366\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.8380 - acc: 0.8600 - val_loss: 2.6519 - val_acc: 0.3354\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4244 - acc: 0.9000 - val_loss: 2.3702 - val_acc: 0.3669\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1692 - acc: 0.9900 - val_loss: 2.0890 - val_acc: 0.4101\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0590 - acc: 1.0000 - val_loss: 1.9705 - val_acc: 0.4301\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0237 - acc: 1.0000 - val_loss: 2.0539 - val_acc: 0.4264\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0117 - acc: 1.0000 - val_loss: 2.2983 - val_acc: 0.4042\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0087 - acc: 1.0000 - val_loss: 2.5993 - val_acc: 0.3773\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0086 - acc: 1.0000 - val_loss: 2.8316 - val_acc: 0.3680\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0050 - acc: 1.0000 - val_loss: 2.9846 - val_acc: 0.3685\n",
      "Epoch 00013: early stopping\n",
      "Train on 781 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 3.9201 - acc: 0.1088 - val_loss: 1.9500 - val_acc: 0.3078\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.0583 - acc: 0.2996 - val_loss: 1.5751 - val_acc: 0.5079\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.5308 - acc: 0.6901 - val_loss: 0.9093 - val_acc: 0.6880\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6700 - acc: 0.9117 - val_loss: 0.8054 - val_acc: 0.7577\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.1469 - acc: 0.9859 - val_loss: 0.8191 - val_acc: 0.7810\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0178 - acc: 1.0000 - val_loss: 0.9148 - val_acc: 0.7833\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.9675 - val_acc: 0.7789\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9444 - val_acc: 0.7849\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9345 - val_acc: 0.7890\n",
      "Epoch 10/100\n",
      " - 0s - loss: 7.9838e-04 - acc: 1.0000 - val_loss: 0.9467 - val_acc: 0.7934\n",
      "Epoch 11/100\n",
      " - 0s - loss: 6.3986e-04 - acc: 1.0000 - val_loss: 0.9557 - val_acc: 0.7948\n",
      "Epoch 00011: early stopping\n",
      "Train on 3125 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.4617 - acc: 0.1994 - val_loss: 0.7398 - val_acc: 0.7538\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.5529 - acc: 0.5530 - val_loss: 0.5126 - val_acc: 0.8459\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5135 - acc: 0.8880 - val_loss: 0.5254 - val_acc: 0.8632\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0606 - acc: 0.9901 - val_loss: 0.6643 - val_acc: 0.8533\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0211 - acc: 0.9942 - val_loss: 0.6496 - val_acc: 0.8648\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0079 - acc: 0.9978 - val_loss: 0.7043 - val_acc: 0.8627\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0193 - acc: 0.9958 - val_loss: 1.1425 - val_acc: 0.7931\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0408 - acc: 0.9939 - val_loss: 0.6176 - val_acc: 0.8753\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0115 - acc: 0.9955 - val_loss: 0.8032 - val_acc: 0.8528\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0121 - acc: 0.9965 - val_loss: 0.7790 - val_acc: 0.8660\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0328 - acc: 0.9914 - val_loss: 0.8319 - val_acc: 0.8409\n",
      "Epoch 00011: early stopping\n",
      "Train on 12500 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 2.1490 - acc: 0.2336 - val_loss: 0.3265 - val_acc: 0.8986\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.7883 - acc: 0.3630 - val_loss: 0.3266 - val_acc: 0.9053\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1487 - acc: 0.6283 - val_loss: 0.5091 - val_acc: 0.8856\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3274 - acc: 0.9116 - val_loss: 0.5473 - val_acc: 0.9048\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.0847 - acc: 0.9824 - val_loss: 0.5827 - val_acc: 0.9145\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.0461 - acc: 0.9920 - val_loss: 0.7076 - val_acc: 0.9048\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0549 - acc: 0.9904 - val_loss: 0.6635 - val_acc: 0.9101\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0267 - acc: 0.9943 - val_loss: 0.8234 - val_acc: 0.8959\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0164 - acc: 0.9969 - val_loss: 0.6617 - val_acc: 0.9224\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0068 - acc: 0.9988 - val_loss: 0.7631 - val_acc: 0.9108\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0065 - acc: 0.9988 - val_loss: 0.5707 - val_acc: 0.9297\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0028 - acc: 0.9994 - val_loss: 0.6718 - val_acc: 0.9214\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.0112 - acc: 0.9987 - val_loss: 1.2144 - val_acc: 0.8720\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.0232 - acc: 0.9962 - val_loss: 0.7437 - val_acc: 0.9144\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.0316 - acc: 0.9942 - val_loss: 0.9357 - val_acc: 0.9023\n",
      "Epoch 00015: early stopping\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.9650 - acc: 0.2549 - val_loss: 0.2082 - val_acc: 0.9329\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.8623 - acc: 0.2965 - val_loss: 0.1899 - val_acc: 0.9426\n",
      "Epoch 3/100\n",
      " - 7s - loss: 1.7023 - acc: 0.3866 - val_loss: 0.2131 - val_acc: 0.9397\n",
      "Epoch 4/100\n",
      " - 7s - loss: 1.2665 - acc: 0.5612 - val_loss: 0.2411 - val_acc: 0.9463\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.8039 - acc: 0.7258 - val_loss: 0.3004 - val_acc: 0.9490\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.5403 - acc: 0.8160 - val_loss: 0.4431 - val_acc: 0.9346\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.3910 - acc: 0.8681 - val_loss: 0.5327 - val_acc: 0.9320\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.3178 - acc: 0.8953 - val_loss: 0.4153 - val_acc: 0.9491\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.2727 - acc: 0.9139 - val_loss: 0.4232 - val_acc: 0.9510\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.2274 - acc: 0.9267 - val_loss: 0.4382 - val_acc: 0.9490\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.2120 - acc: 0.9313 - val_loss: 0.5581 - val_acc: 0.9367\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.2008 - acc: 0.9368 - val_loss: 0.4979 - val_acc: 0.9459\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.1801 - acc: 0.9446 - val_loss: 0.4940 - val_acc: 0.9439\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.1579 - acc: 0.9503 - val_loss: 0.5096 - val_acc: 0.9417\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.1568 - acc: 0.9526 - val_loss: 0.4450 - val_acc: 0.9537\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.1454 - acc: 0.9560 - val_loss: 0.3968 - val_acc: 0.9587\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.1251 - acc: 0.9620 - val_loss: 0.4105 - val_acc: 0.9566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      " - 7s - loss: 0.1210 - acc: 0.9639 - val_loss: 0.4755 - val_acc: 0.9511\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.1212 - acc: 0.9637 - val_loss: 0.4744 - val_acc: 0.9541\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.1180 - acc: 0.9640 - val_loss: 0.4494 - val_acc: 0.9547\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.1003 - acc: 0.9693 - val_loss: 0.4661 - val_acc: 0.9534\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.1042 - acc: 0.9685 - val_loss: 0.4555 - val_acc: 0.9538\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.1063 - acc: 0.9691 - val_loss: 0.5846 - val_acc: 0.9443\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.1097 - acc: 0.9686 - val_loss: 0.4970 - val_acc: 0.9537\n",
      "Epoch 25/100\n",
      " - 7s - loss: 0.1027 - acc: 0.9703 - val_loss: 0.4530 - val_acc: 0.9547\n",
      "Epoch 26/100\n",
      " - 7s - loss: 0.0858 - acc: 0.9741 - val_loss: 0.5540 - val_acc: 0.9502\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.0840 - acc: 0.9770 - val_loss: 0.4940 - val_acc: 0.9557\n",
      "Epoch 28/100\n",
      " - 7s - loss: 0.1037 - acc: 0.9725 - val_loss: 0.5844 - val_acc: 0.9489\n",
      "Epoch 29/100\n",
      " - 7s - loss: 0.0927 - acc: 0.9734 - val_loss: 0.5834 - val_acc: 0.9480\n",
      "Epoch 30/100\n",
      " - 7s - loss: 0.0850 - acc: 0.9757 - val_loss: 0.4951 - val_acc: 0.9546\n",
      "Epoch 31/100\n",
      " - 7s - loss: 0.0754 - acc: 0.9793 - val_loss: 0.6245 - val_acc: 0.9473\n",
      "Epoch 32/100\n",
      " - 7s - loss: 0.0773 - acc: 0.9784 - val_loss: 0.6178 - val_acc: 0.9476\n",
      "Epoch 33/100\n",
      " - 7s - loss: 0.0784 - acc: 0.9789 - val_loss: 0.5955 - val_acc: 0.9502\n",
      "Epoch 34/100\n",
      " - 7s - loss: 0.0749 - acc: 0.9789 - val_loss: 0.4865 - val_acc: 0.9575\n",
      "Epoch 35/100\n",
      " - 7s - loss: 0.0796 - acc: 0.9793 - val_loss: 0.4464 - val_acc: 0.9602\n",
      "Epoch 36/100\n",
      " - 7s - loss: 0.0782 - acc: 0.9786 - val_loss: 0.5153 - val_acc: 0.9552\n",
      "Epoch 00036: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_train = [100, 781, 3125, 12500, 50000]\n",
    "noise_levels = [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "#noise_levels = [0.0, 0.2]\n",
    "Overall_time_1 = []\n",
    "for n_level in noise_levels:\n",
    "    time_conv = []\n",
    "    for num in total_train:\n",
    "        ## Sample num samples\n",
    "        ix = random.sample(range(0, len(X_train)), num)\n",
    "        X_data = X_train[ix]\n",
    "        Y_data = Y_train[ix]\n",
    "        x_data = Add_noise(n_level, X_data)\n",
    "        \n",
    "        model = build_network(params['activation'], params['layers'], params['input_dim'], params['output_dim'])\n",
    "        start = time.time()\n",
    "        earlystop = EarlyStopping(monitor='acc', min_delta=0.001, patience=5, \n",
    "                          verbose=1, mode='auto')\n",
    "        callbacks_list = [earlystop]\n",
    "        r = model.fit(x=x_data, y=Y_data, \n",
    "                      verbose = 2, \n",
    "                      batch_size = params['batch_size'],\n",
    "                      epochs     = 100,\n",
    "                      validation_data=(X_test, Y_test),\n",
    "                      callbacks = callbacks_list,\n",
    "                      shuffle=True)\n",
    "        end = time.time()\n",
    "        time_conv.append(end - start)\n",
    "    #time_conv = [z/float(max(time_conv)) for z in time_conv]\n",
    "    Overall_time_1.append(time_conv)\n",
    "    plt.plot(time_conv,  label = 'noise_level '+ str(n_level))\n",
    "\n",
    "plt.xlabel('Examples')\n",
    "plt.ylabel('Time to convergence')\n",
    "plt.xticks(np.arange(5), [100, 781, 3125, 12500, 50000])\n",
    "plt.legend()\n",
    "plt.savefig('time_to_conv_samples.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7.245622158050537,\n",
       "  3.880950927734375,\n",
       "  6.2473390102386475,\n",
       "  30.458383083343506,\n",
       "  151.15747380256653],\n",
       " [2.7828121185302734,\n",
       "  3.851668119430542,\n",
       "  7.653772830963135,\n",
       "  28.84587812423706,\n",
       "  73.17207312583923],\n",
       " [3.0980899333953857,\n",
       "  4.805349111557007,\n",
       "  8.943825960159302,\n",
       "  23.765146017074585,\n",
       "  172.80469179153442],\n",
       " [3.1133620738983154,\n",
       "  4.246937036514282,\n",
       "  8.43122410774231,\n",
       "  27.780154943466187,\n",
       "  186.81553506851196],\n",
       " [3.510531187057495,\n",
       "  4.10051703453064,\n",
       "  7.504204988479614,\n",
       "  28.098464012145996,\n",
       "  239.03502082824707]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Overall_time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
